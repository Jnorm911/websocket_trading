{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import talib\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.models import Sequential\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    df = pd.read_csv(data_path)\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df[\"color_change\"] = df[\"color\"].diff().ne(0).astype(int)\n",
    "    df[\"color_change\"].fillna(0, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def scale_data(df):\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "    return df_scaled\n",
    "\n",
    "\n",
    "def add_heiken_ashi_features(df):\n",
    "    # Create Heiken Ashi DataFrame\n",
    "    ha_df = df.ta.ha()\n",
    "\n",
    "    # Rename the HA columns\n",
    "    ha_df.columns = [f\"HA_{col}\" for col in ha_df.columns]\n",
    "\n",
    "    # Join the HA columns to the original dataframe\n",
    "    df = df.join(ha_df)\n",
    "\n",
    "    # Heiken Ashi Close to Open\n",
    "    df[\"HA_close_open\"] = df[\"HA_close\"] - df[\"HA_open\"]\n",
    "\n",
    "    # Heiken Ashi High Low Range\n",
    "    df[\"HA_high_low\"] = df[\"HA_high\"] - df[\"HA_low\"]\n",
    "\n",
    "    # Heiken Ashi Body Range\n",
    "    df[\"HA_body\"] = abs(df[\"HA_close\"] - df[\"HA_open\"])\n",
    "\n",
    "    # Heiken Ashi Price Direction\n",
    "    df[\"HA_direction\"] = (df[\"HA_close\"] > df[\"HA_open\"]).astype(int)\n",
    "\n",
    "    # Heiken Ashi Volume-weighted Price\n",
    "    df[\"HA_vwap\"] = (df[\"HA_close\"] * df[\"volume\"]).cumsum() / df[\"volume\"].cumsum()\n",
    "\n",
    "    # Lag 1 feature\n",
    "    df[\"HA_close_lag1\"] = df[\"HA_close\"].shift(1)\n",
    "\n",
    "    # Close Change\n",
    "    df[\"HA_close_change\"] = df[\"HA_close\"].diff()\n",
    "\n",
    "    # Close % Change\n",
    "    df[\"HA_close_pct_change\"] = df[\"HA_close\"].pct_change()\n",
    "\n",
    "    # 5-period Simple Moving Average\n",
    "    df[\"HA_sma5\"] = df[\"HA_close\"].rolling(5).mean()\n",
    "\n",
    "    # 5-period Exponential Moving Average\n",
    "    df[\"HA_ema5\"] = df[\"HA_close\"].ewm(span=5).mean()\n",
    "\n",
    "    # Additional features\n",
    "    df[\"HA_ema10\"] = df[\"HA_close\"].ewm(span=10).mean()\n",
    "    df[\"HA_ema15\"] = df[\"HA_close\"].ewm(span=15).mean()\n",
    "    df[\"HA_pct_diff_ema5_15\"] = (\n",
    "        (df[\"HA_ema5\"] - df[\"HA_ema15\"]) / df[\"HA_ema15\"]\n",
    "    ) * 100\n",
    "    df[\"HA_rsi\"] = ta.rsi(df[\"HA_close\"])\n",
    "    # Calculate Short Term Exponential Moving Average\n",
    "    df[\"short_ema\"] = df[\"HA_close\"].ewm(span=12, adjust=False).mean()\n",
    "\n",
    "    # Calculate Long Term Exponential Moving Average\n",
    "    df[\"long_ema\"] = df[\"HA_close\"].ewm(span=26, adjust=False).mean()\n",
    "\n",
    "    # Calculate Moving Average Convergence Divergence (MACD)\n",
    "    df[\"HA_macd\"] = df[\"short_ema\"] - df[\"long_ema\"]\n",
    "\n",
    "    # Calculate Signal Line\n",
    "    df[\"HA_macds\"] = df[\"HA_macd\"].ewm(span=9, adjust=False).mean()\n",
    "\n",
    "    # Calculate MACD Histogram\n",
    "    df[\"HA_macdh\"] = df[\"HA_macd\"] - df[\"HA_macds\"]\n",
    "\n",
    "    # Drop temporary short_ema and long_ema columns\n",
    "    df = df.drop([\"short_ema\", \"long_ema\"], axis=1)\n",
    "\n",
    "    df[\"HA_cci\"] = ta.cci(df[\"HA_high\"], df[\"HA_low\"], df[\"HA_close\"])\n",
    "    df[\"HA_atr\"] = ta.atr(df[\"HA_high\"], df[\"HA_low\"], df[\"HA_close\"])\n",
    "    df[\"HA_ha_close_bbp50_std\"] = (\n",
    "        ta.stdev(df[\"HA_close\"], 50) / df[\"HA_close\"]\n",
    "    )  # Bollinger Bands normalized width\n",
    "    df[\"HA_mfi\"] = ta.mfi(df[\"HA_high\"], df[\"HA_low\"], df[\"HA_close\"], df[\"volume\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def compute_renko(df, brick_size):\n",
    "    renko_df = pd.DataFrame(index=df.index, columns=[\"open\", \"high\", \"low\", \"close\"])\n",
    "    current_price = df[\"close\"][0]\n",
    "    last_reset_price = current_price\n",
    "\n",
    "    for idx in df.index[1:]:\n",
    "        current_price = df.loc[idx, \"close\"]\n",
    "\n",
    "        while last_reset_price + brick_size <= current_price:\n",
    "            renko_df.loc[idx] = [\n",
    "                last_reset_price,\n",
    "                last_reset_price + brick_size,\n",
    "                last_reset_price,\n",
    "                last_reset_price + brick_size,\n",
    "            ]\n",
    "            last_reset_price += brick_size\n",
    "\n",
    "        while last_reset_price - brick_size >= current_price:\n",
    "            renko_df.loc[idx] = [\n",
    "                last_reset_price,\n",
    "                last_reset_price - brick_size,\n",
    "                last_reset_price - brick_size,\n",
    "                last_reset_price,\n",
    "            ]\n",
    "            last_reset_price -= brick_size\n",
    "\n",
    "    return renko_df.dropna()\n",
    "\n",
    "\n",
    "def add_renko_features(df, renko_df):\n",
    "    # Append \"_renko\" to the column names of renko_df\n",
    "    renko_df.columns = [str(col) + \"_renko\" for col in renko_df.columns]\n",
    "\n",
    "    # Add EMA, SMA, WMA, RSI, and Bollinger Bands to renko_df\n",
    "    renko_df[\"sma_renko\"] = talib.SMA(renko_df[\"close_renko\"], timeperiod=5)\n",
    "    renko_df[\"ema_renko\"] = talib.EMA(renko_df[\"close_renko\"], timeperiod=5)\n",
    "    renko_df[\"wma_renko\"] = talib.WMA(renko_df[\"close_renko\"], timeperiod=5)\n",
    "    renko_df[\"rsi_renko\"] = talib.RSI(renko_df[\"close_renko\"], timeperiod=5)\n",
    "    (\n",
    "        renko_df[\"upper_band_renko\"],\n",
    "        renko_df[\"middle_band_renko\"],\n",
    "        renko_df[\"lower_band_renko\"],\n",
    "    ) = talib.BBANDS(\n",
    "        renko_df[\"close_renko\"], timeperiod=5\n",
    "    )  # Join Renko data with the original DataFrame\n",
    "    df = df.join(renko_df)\n",
    "\n",
    "    # Derived features\n",
    "    df[\"close_open_renko\"] = df[\"close_renko\"] - df[\"open_renko\"]\n",
    "    df[\"high_low_renko\"] = df[\"high_renko\"] - df[\"low_renko\"]\n",
    "    df[\"close_renko_lag1\"] = df[\"close_renko\"].shift(1)\n",
    "    df[\"close_change_renko\"] = df[\"close_renko\"].diff()\n",
    "    df[\"renko_open_lag1\"] = df[\"open_renko\"].shift(1)\n",
    "    df[\"renko_high_lag1\"] = df[\"high_renko\"].shift(1)\n",
    "    df[\"renko_low_lag1\"] = df[\"low_renko\"].shift(1)\n",
    "    df[\"renko_volume_lag1\"] = df[\"volume\"].shift(1)\n",
    "    # Compute the 'renko_uptrend' feature\n",
    "    df[\"renko_uptrend\"] = df[\"close_renko\"].diff().apply(lambda x: int(x > 0))\n",
    "\n",
    "    # Fill NaN values using forward fill and backward fill\n",
    "    df[\"renko_uptrend\"].ffill(inplace=True)\n",
    "    df[\"renko_uptrend\"].bfill(inplace=True)\n",
    "    df[\"direction_renko\"] = df[\"renko_uptrend\"].astype(int)\n",
    "    df[\"direction_change\"] = df[\"direction_renko\"].diff().abs()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def kagi(df):\n",
    "    timestamps = [df.index[0]]  # Store timestamps for the kagi_df index\n",
    "    kagi_data = []\n",
    "    cur_col = {\"dir\": \"up\", \"start\": df[\"close\"].iloc[0]}\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        cp = row[\"close\"]\n",
    "        diff = cp - cur_col[\"start\"]\n",
    "\n",
    "        if cur_col[\"dir\"] == \"up\":\n",
    "            if diff < 0:\n",
    "                kagi_data.append(cur_col)\n",
    "                cur_col = {\"dir\": \"down\", \"start\": cp}\n",
    "                timestamps.append(index)\n",
    "            else:\n",
    "                cur_col[\"start\"] += diff\n",
    "        else:\n",
    "            if diff > 0:\n",
    "                kagi_data.append(cur_col)\n",
    "                cur_col = {\"dir\": \"up\", \"start\": cp}\n",
    "                timestamps.append(index)\n",
    "            else:\n",
    "                cur_col[\"start\"] -= diff\n",
    "\n",
    "    kagi_data.append(cur_col)\n",
    "    kagi_df = pd.DataFrame(kagi_data, index=timestamps)\n",
    "    return kagi_df\n",
    "\n",
    "\n",
    "def add_kagi_features(df, kagi_df):\n",
    "    kagi_df[\"sma\"] = talib.SMA(kagi_df[\"start\"], 5)\n",
    "    kagi_df[\"ema\"] = talib.EMA(kagi_df[\"start\"], 5)\n",
    "    kagi_df[\"wma\"] = talib.WMA(kagi_df[\"start\"], 5)\n",
    "    kagi_df[\"macd\"], kagi_df[\"macdsig\"], kagi_df[\"macdhist\"] = talib.MACD(\n",
    "        kagi_df[\"start\"], 12, 26, 9\n",
    "    )\n",
    "    kagi_df[\"rsi\"] = talib.RSI(kagi_df[\"start\"], 14)\n",
    "    kagi_df[\"upper\"], kagi_df[\"mid\"], kagi_df[\"lower\"] = talib.BBANDS(\n",
    "        kagi_df[\"start\"], 5\n",
    "    )\n",
    "    kagi_df[\"adx\"] = talib.ADX(kagi_df[\"start\"], kagi_df[\"start\"], kagi_df[\"start\"], 14)\n",
    "    kagi_df[\"atr\"] = talib.ATR(kagi_df[\"start\"], kagi_df[\"start\"], kagi_df[\"start\"], 14)\n",
    "    kagi_df[\"slowk\"], kagi_df[\"slowd\"] = talib.STOCH(\n",
    "        kagi_df[\"start\"], kagi_df[\"start\"], kagi_df[\"start\"], 5, 3, 0, 3, 0\n",
    "    )\n",
    "    # Align the volume series with kagi_df\n",
    "    aligned_volume = df[\"volume\"].reindex(kagi_df.index, method=\"pad\")\n",
    "\n",
    "    # Calculate Accumulation / Distribution Line\n",
    "    kagi_df[\"ad\"] = talib.AD(\n",
    "        kagi_df[\"start\"], kagi_df[\"start\"], kagi_df[\"start\"], aligned_volume\n",
    "    )\n",
    "\n",
    "    # Calculate On Balance Volume\n",
    "    obv = talib.OBV(kagi_df[\"start\"], aligned_volume)\n",
    "    kagi_df[\"obv\"] = (obv - obv.min()) / (obv.max() - obv.min())\n",
    "\n",
    "    kagi_df[\"roc\"] = talib.ROC(kagi_df[\"start\"], 10)\n",
    "    return kagi_df.add_prefix(\"kagi_\")\n",
    "\n",
    "\n",
    "def point_and_figure(df, box_size=1, reversal=3):\n",
    "    pnf_data = []\n",
    "    current_column = {\"direction\": \"up\", \"start_price\": df[\"close\"].iloc[0], \"boxes\": 1}\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        current_price = row[\"close\"]\n",
    "        box_diff = abs(current_price - current_column[\"start_price\"]) / box_size\n",
    "\n",
    "        if current_column[\"direction\"] == \"up\":\n",
    "            if box_diff >= reversal and current_price < current_column[\"start_price\"]:\n",
    "                pnf_data.append(current_column)\n",
    "                current_column = {\n",
    "                    \"direction\": \"down\",\n",
    "                    \"start_price\": current_price,\n",
    "                    \"boxes\": 1,\n",
    "                }\n",
    "            elif box_diff >= 1:\n",
    "                current_column[\"boxes\"] += int(box_diff)\n",
    "                current_column[\"start_price\"] += int(box_diff) * box_size\n",
    "        else:\n",
    "            if box_diff >= reversal and current_price > current_column[\"start_price\"]:\n",
    "                pnf_data.append(current_column)\n",
    "                current_column = {\n",
    "                    \"direction\": \"up\",\n",
    "                    \"start_price\": current_price,\n",
    "                    \"boxes\": 1,\n",
    "                }\n",
    "            elif box_diff >= 1:\n",
    "                current_column[\"boxes\"] += int(box_diff)\n",
    "                current_column[\"start_price\"] -= int(box_diff) * box_size\n",
    "\n",
    "    pnf_data.append(current_column)\n",
    "    pnf_df = pd.DataFrame(pnf_data)\n",
    "    pnf_df[\"time\"] = df.index\n",
    "    return pnf_df\n",
    "\n",
    "\n",
    "def add_point_and_figure_features(pnf_df):\n",
    "    # Calculate moving averages\n",
    "    pnf_df[\"sma\"] = talib.SMA(pnf_df[\"start_price\"], timeperiod=5)\n",
    "    pnf_df[\"ema\"] = talib.EMA(pnf_df[\"start_price\"], timeperiod=5)\n",
    "    pnf_df[\"wma\"] = talib.WMA(pnf_df[\"start_price\"], timeperiod=5)\n",
    "\n",
    "    # Calculate MACD\n",
    "    pnf_df[\"macd\"], pnf_df[\"macdsignal\"], pnf_df[\"macdhist\"] = talib.MACD(\n",
    "        pnf_df[\"start_price\"], fastperiod=12, slowperiod=26, signalperiod=9\n",
    "    )\n",
    "\n",
    "    # Calculate RSI\n",
    "    pnf_df[\"rsi\"] = talib.RSI(pnf_df[\"start_price\"], timeperiod=14)\n",
    "\n",
    "    # Calculate Bollinger Bands\n",
    "    pnf_df[\"upper_band\"], pnf_df[\"middle_band\"], pnf_df[\"lower_band\"] = talib.BBANDS(\n",
    "        pnf_df[\"start_price\"], timeperiod=5\n",
    "    )\n",
    "\n",
    "    # Calculate ADX\n",
    "    pnf_df[\"adx\"] = talib.ADX(\n",
    "        pnf_df[\"start_price\"],\n",
    "        pnf_df[\"start_price\"],\n",
    "        pnf_df[\"start_price\"],\n",
    "        timeperiod=14,\n",
    "    )\n",
    "\n",
    "    # Calculate ATR\n",
    "    pnf_df[\"atr\"] = talib.ATR(\n",
    "        pnf_df[\"start_price\"],\n",
    "        pnf_df[\"start_price\"],\n",
    "        pnf_df[\"start_price\"],\n",
    "        timeperiod=14,\n",
    "    )\n",
    "\n",
    "    # Calculate Stochastic Oscillator\n",
    "    pnf_df[\"slowk\"], pnf_df[\"slowd\"] = talib.STOCH(\n",
    "        pnf_df[\"start_price\"],\n",
    "        pnf_df[\"start_price\"],\n",
    "        pnf_df[\"start_price\"],\n",
    "        fastk_period=5,\n",
    "        slowk_period=3,\n",
    "        slowk_matype=0,\n",
    "        slowd_period=3,\n",
    "        slowd_matype=0,\n",
    "    )\n",
    "\n",
    "    # Calculate Accumulation / Distribution Line\n",
    "    pnf_df[\"ad\"] = talib.AD(\n",
    "        pnf_df[\"start_price\"],\n",
    "        pnf_df[\"start_price\"],\n",
    "        pnf_df[\"start_price\"],\n",
    "        pnf_df[\"boxes\"],\n",
    "    )\n",
    "\n",
    "    # Calculate On Balance Volume\n",
    "    obv = talib.OBV(pnf_df[\"start_price\"], pnf_df[\"boxes\"])\n",
    "    pnf_df[\"obv\"] = (obv - obv.min()) / (obv.max() - obv.min())\n",
    "\n",
    "    # Calculate Rate of Change\n",
    "    pnf_df[\"roc\"] = talib.ROC(pnf_df[\"start_price\"], timeperiod=10)\n",
    "\n",
    "    return pnf_df.add_prefix(\"pnf_\")\n",
    "\n",
    "\n",
    "# def three_line_break(df, reversal=3):\n",
    "#     tlb_data = [{\"direction\": \"up\", \"start_price\": df.iloc[0, :], \"boxes\": 1}]\n",
    "#     for index, row in df.iterrows():\n",
    "#         last_line = tlb_data[-1]\n",
    "\n",
    "#         if last_line[\"direction\"] == \"up\":\n",
    "#             if row[\"low\"] < last_line[\"start_price\"][\"low\"]:\n",
    "#                 last_line[\"boxes\"] += 1\n",
    "#             elif row[\"high\"] >= last_line[\"start_price\"][\"high\"] * (1 + reversal / 100):\n",
    "#                 tlb_data.append({\"direction\": \"down\", \"start_price\": row, \"boxes\": 1})\n",
    "#         else:\n",
    "#             if row[\"high\"] > last_line[\"start_price\"][\"high\"]:\n",
    "#                 last_line[\"boxes\"] += 1\n",
    "#             elif row[\"low\"] <= last_line[\"start_price\"][\"low\"] * (1 - reversal / 100):\n",
    "#                 tlb_data.append({\"direction\": \"up\", \"start_price\": row, \"boxes\": 1})\n",
    "#     return pd.DataFrame(tlb_data)\n",
    "\n",
    "\n",
    "# def add_three_line_break_features(tlb_df):\n",
    "#     close_prices = tlb_df[\"start_price\"].apply(lambda x: x[\"close\"])\n",
    "#     high_prices = tlb_df[\"start_price\"].apply(lambda x: x[\"high\"])\n",
    "#     low_prices = tlb_df[\"start_price\"].apply(lambda x: x[\"low\"])\n",
    "\n",
    "#     # Calculate moving averages\n",
    "#     tlb_df[\"sma\"] = talib.SMA(close_prices, timeperiod=5)\n",
    "#     tlb_df[\"ema\"] = talib.EMA(close_prices, timeperiod=5)\n",
    "#     tlb_df[\"wma\"] = talib.WMA(close_prices, timeperiod=5)\n",
    "\n",
    "#     # Calculate MACD\n",
    "#     tlb_df[\"macd\"], tlb_df[\"macdsignal\"], tlb_df[\"macdhist\"] = talib.MACD(\n",
    "#         close_prices, fastperiod=12, slowperiod=26, signalperiod=9\n",
    "#     )\n",
    "\n",
    "#     # Calculate RSI\n",
    "#     tlb_df[\"rsi\"] = talib.RSI(close_prices, timeperiod=14)\n",
    "\n",
    "#     # Calculate Bollinger Bands\n",
    "#     tlb_df[\"upper_band\"], tlb_df[\"middle_band\"], tlb_df[\"lower_band\"] = talib.BBANDS(\n",
    "#         close_prices, timeperiod=5\n",
    "#     )\n",
    "\n",
    "#     # Calculate ADX\n",
    "#     tlb_df[\"adx\"] = talib.ADX(high_prices, low_prices, close_prices, timeperiod=14)\n",
    "\n",
    "#     # Calculate ATR\n",
    "#     tlb_df[\"atr\"] = talib.ATR(high_prices, low_prices, close_prices, timeperiod=14)\n",
    "\n",
    "#     # Calculate Stochastic Oscillator\n",
    "#     tlb_df[\"slowk\"], tlb_df[\"slowd\"] = talib.STOCH(\n",
    "#         high_prices,\n",
    "#         low_prices,\n",
    "#         close_prices,\n",
    "#         fastk_period=5,\n",
    "#         slowk_period=3,\n",
    "#         slowk_matype=0,\n",
    "#         slowd_period=3,\n",
    "#         slowd_matype=0,\n",
    "#     )\n",
    "\n",
    "#     # Calculate Accumulation / Distribution Line\n",
    "#     volume = tlb_df[\"start_price\"].apply(lambda x: x[\"volume\"])\n",
    "#     tlb_df[\"ad\"] = talib.AD(high_prices, low_prices, close_prices, volume)\n",
    "\n",
    "#     # Calculate On Balance Volume\n",
    "#     tlb_df[\"obv\"] = talib.OBV(close_prices, volume)\n",
    "\n",
    "#     # Calculate Rate of Change\n",
    "#     tlb_df[\"roc\"] = talib.ROC(close_prices, timeperiod=10)\n",
    "\n",
    "#     return tlb_df.add_prefix(\"tlb_\")\n",
    "\n",
    "\n",
    "def tlb(df, r=3):\n",
    "    data = [{\"d\": \"up\", \"sp\": df.iloc[0, :], \"bx\": 1}]\n",
    "    for i, row in df.iterrows():\n",
    "        ll = data[-1]\n",
    "        if ll[\"d\"] == \"up\":\n",
    "            if row[\"low\"] < ll[\"sp\"][\"low\"]:\n",
    "                ll[\"bx\"] += 1\n",
    "            elif row[\"high\"] >= ll[\"sp\"][\"high\"] * (1 + r / 100):\n",
    "                data.append({\"d\": \"down\", \"sp\": row, \"bx\": 1})\n",
    "        else:\n",
    "            if row[\"high\"] > ll[\"sp\"][\"high\"]:\n",
    "                ll[\"bx\"] += 1\n",
    "            elif row[\"low\"] <= ll[\"sp\"][\"low\"] * (1 - r / 100):\n",
    "                data.append({\"d\": \"up\", \"sp\": row, \"bx\": 1})\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "def add_tlb_ft(tlb_df):\n",
    "    p = lambda x: (x[\"close\"], x[\"high\"], x[\"low\"], x[\"volume\"])\n",
    "    cl_hl_lv = tlb_df[\"sp\"].apply(p)\n",
    "    c, h, l, v = map(np.array, zip(*cl_hl_lv))\n",
    "\n",
    "    ft = {}\n",
    "    for fn, tp in (\n",
    "        (\"SMA\", 5),\n",
    "        (\"EMA\", 5),\n",
    "        (\"WMA\", 5),\n",
    "        (\"MACD\", None),\n",
    "        (\"RSI\", 14),\n",
    "        (\"upper_band\", 5),\n",
    "        (\"ADX\", 14),\n",
    "        (\"ATR\", 14),\n",
    "        (\"slowk\", None),\n",
    "        (\"AD\", None),\n",
    "        (\"OBV\", None),\n",
    "        (\"ROC\", 10),\n",
    "    ):\n",
    "        if fn in [\"SMA\", \"EMA\", \"WMA\"]:\n",
    "            ft[fn] = getattr(talib, fn)(c, tp)\n",
    "        elif fn == \"MACD\":\n",
    "            ft[\"macd\"], ft[\"macdsignal\"], ft[\"macdhist\"] = talib.MACD(c, 12, 26, 9)\n",
    "        elif fn == \"upper_band\":\n",
    "            ft[fn], ft[\"middle_band\"], ft[\"lower_band\"] = talib.BBANDS(c, tp)\n",
    "        elif fn == \"slowk\":\n",
    "            ft[\"slowk\"], ft[\"slowd\"] = talib.STOCH(h, l, c, 5, 3, 0, 3, 0)\n",
    "        elif fn == \"AD\":\n",
    "            ft[fn] = talib.AD(h, l, c, v)\n",
    "        elif fn == \"OBV\":\n",
    "            ft[fn] = talib.OBV(c, v)\n",
    "        else:\n",
    "            ft[fn] = getattr(talib, fn)(c, tp)\n",
    "    ft = pd.DataFrame(ft)\n",
    "    return ft.add_prefix(\"tlb_\")\n",
    "\n",
    "\n",
    "def create_features(df):\n",
    "    ## DIFFERENCES ##\n",
    "\n",
    "    # Price differences\n",
    "    df[\"price_diff\"] = df[\"close\"].diff()\n",
    "    df[\"op_cl_diff\"] = df[\"open\"] - df[\"close\"]\n",
    "\n",
    "    # Moving averages\n",
    "    df[\"ma_5\"] = df[\"close\"].rolling(window=5).mean()\n",
    "    df[\"ma_10\"] = df[\"close\"].rolling(window=10).mean()\n",
    "\n",
    "    # Price percentage change\n",
    "    df[\"pct_change\"] = df[\"close\"].pct_change()\n",
    "\n",
    "    # RSI\n",
    "    delta = df[\"close\"].diff()\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "    avg_gain = gain.rolling(window=14).mean()\n",
    "    avg_loss = loss.rolling(window=14).mean()\n",
    "    rs = avg_gain / avg_loss\n",
    "    df[\"rsi\"] = 100 - 100 / (1 + rs)\n",
    "\n",
    "    # Other popular difference features\n",
    "    for i in range(1, 35):\n",
    "        df[\"diff_{}\".format(i)] = df[\"close\"].diff(i)\n",
    "\n",
    "    sma = df[\"close\"].rolling(window=20).mean()\n",
    "    std = df[\"close\"].rolling(window=20).std()\n",
    "    df[\"upper_band\"] = sma + (2 * std)\n",
    "    df[\"lower_band\"] = sma - (2 * std)\n",
    "\n",
    "    highest_high = df[\"high\"].rolling(window=14).max()\n",
    "    lowest_low = df[\"low\"].rolling(window=14).min()\n",
    "    df[\"williams_r\"] = (highest_high - df[\"close\"]) / (highest_high - lowest_low) * -100\n",
    "\n",
    "    df[\"obv\"] = (np.sign(df[\"close\"].diff()) * df[\"volume\"]).fillna(0).cumsum()\n",
    "\n",
    "    tp = (df[\"high\"] + df[\"low\"] + df[\"close\"]) / 3\n",
    "    sma = tp.rolling(window=20).mean()\n",
    "    mean_deviation = tp.rolling(window=20).apply(\n",
    "        lambda x: np.mean(np.abs(x - x.mean()))\n",
    "    )\n",
    "    df[\"cci\"] = (tp - sma) / (0.015 * mean_deviation)\n",
    "\n",
    "    true_range = pd.concat(\n",
    "        [\n",
    "            df[\"high\"] - df[\"low\"],\n",
    "            (df[\"high\"] - df[\"close\"].shift()).abs(),\n",
    "            (df[\"close\"].shift() - df[\"low\"]).abs(),\n",
    "        ],\n",
    "        axis=1,\n",
    "    ).max(axis=1)\n",
    "    df[\"atr\"] = true_range.rolling(window=14).mean()\n",
    "\n",
    "    money_flow_vol = (\n",
    "        ((df[\"close\"] - df[\"low\"]) - (df[\"high\"] - df[\"close\"]))\n",
    "        / (df[\"high\"] - df[\"low\"])\n",
    "        * df[\"volume\"]\n",
    "    )\n",
    "    cmf = (\n",
    "        money_flow_vol.rolling(window=20).sum() / df[\"volume\"].rolling(window=20).sum()\n",
    "    )\n",
    "    df[\"cmf\"] = cmf\n",
    "\n",
    "    ema_12 = df[\"close\"].ewm(span=12).mean()\n",
    "    ema_26 = df[\"close\"].ewm(span=26).mean()\n",
    "    ppo = (ema_12 - ema_26) / ema_26 * 100\n",
    "    df[\"ppo\"] = ppo\n",
    "\n",
    "    ### LAG ###\n",
    "\n",
    "    # Lag closing prices\n",
    "    for i in range(1, 11):\n",
    "        df[\"lag_close_{}\".format(i)] = df[\"close\"].shift(i)\n",
    "\n",
    "    # Lag daily returns\n",
    "    returns = df[\"close\"].pct_change()\n",
    "    for i in range(1, 6):\n",
    "        df[\"lag_return_{}\".format(i)] = returns.shift(i)\n",
    "\n",
    "    # Lag high and low prices\n",
    "    for i in range(1, 4):\n",
    "        df[\"lag_high_{}\".format(i)] = df[\"high\"].shift(i)\n",
    "        df[\"lag_low_{}\".format(i)] = df[\"low\"].shift(i)\n",
    "\n",
    "    # Historical volatility\n",
    "    df[\"hist_volatility_10\"] = returns.rolling(window=10).std()\n",
    "    df[\"hist_volatility_20\"] = returns.rolling(window=20).std()\n",
    "    df[\"hist_volatility_30\"] = returns.rolling(window=30).std()\n",
    "\n",
    "    # Previous day's RSI value\n",
    "    delta = df[\"close\"].diff()\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "    avg_gain = gain.rolling(window=14).mean()\n",
    "    avg_loss = loss.rolling(window=14).mean()\n",
    "    rs = avg_gain / avg_loss\n",
    "    rsi = 100 - 100 / (1 + rs)\n",
    "    df[\"lag_rsi_1\"] = rsi.shift(1)\n",
    "\n",
    "    ### ROLLING ###\n",
    "\n",
    "    # Moving averages\n",
    "    df[\"ma_5\"] = df[\"close\"].rolling(window=5).mean()\n",
    "    df[\"ma_10\"] = df[\"close\"].rolling(window=10).mean()\n",
    "    df[\"ma_20\"] = df[\"close\"].rolling(window=20).mean()\n",
    "\n",
    "    # Exponential moving averages\n",
    "    df[\"ema_5\"] = df[\"close\"].ewm(span=5).mean()\n",
    "    df[\"ema_10\"] = df[\"close\"].ewm(span=10).mean()\n",
    "    df[\"ema_20\"] = df[\"close\"].ewm(span=20).mean()\n",
    "\n",
    "    # Bollinger Bands\n",
    "    sma = df[\"close\"].rolling(window=20).mean()\n",
    "    std = df[\"close\"].rolling(window=20).std()\n",
    "    df[\"upper_band\"] = sma + (2 * std)\n",
    "    df[\"lower_band\"] = sma - (2 * std)\n",
    "\n",
    "    # Rate of Change (ROC)\n",
    "    df[\"roc_5\"] = df[\"close\"].pct_change(periods=5)\n",
    "    df[\"roc_10\"] = df[\"close\"].pct_change(periods=10)\n",
    "\n",
    "    # Standard deviation\n",
    "    df[\"std_5\"] = df[\"close\"].rolling(window=5).std()\n",
    "    df[\"std_10\"] = df[\"close\"].rolling(window=10).std()\n",
    "\n",
    "    # Average True Range (ATR)\n",
    "    true_range = pd.concat(\n",
    "        [\n",
    "            df[\"high\"] - df[\"low\"],\n",
    "            (df[\"high\"] - df[\"close\"].shift()).abs(),\n",
    "            (df[\"low\"] - df[\"close\"].shift()).abs(),\n",
    "        ],\n",
    "        axis=1,\n",
    "    ).max(axis=1)\n",
    "    df[\"atr_14\"] = true_range.rolling(window=14).mean()\n",
    "\n",
    "    # Keltner Channels\n",
    "    middle_line = df[\"close\"].rolling(window=20).mean()\n",
    "    upper_keltner = middle_line + 2 * df[\"atr_14\"]\n",
    "    lower_keltner = middle_line - 2 * df[\"atr_14\"]\n",
    "    df[\"upper_keltner\"] = upper_keltner\n",
    "    df[\"lower_keltner\"] = lower_keltner\n",
    "\n",
    "    # RSI\n",
    "    delta = df[\"close\"].diff()\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "    avg_gain = gain.rolling(window=14).mean()\n",
    "    avg_loss = loss.rolling(window=14).mean()\n",
    "    rs = avg_gain / avg_loss\n",
    "    df[\"rsi\"] = 100 - 100 / (1 + rs)\n",
    "\n",
    "    ### RATIO ###\n",
    "\n",
    "    # Calculate some basic features first\n",
    "    returns = df[\"close\"].pct_change()\n",
    "    ema_12 = df[\"close\"].ewm(span=12).mean()\n",
    "    ema_26 = df[\"close\"].ewm(span=26).mean()\n",
    "\n",
    "    # 1. Price-to-moving-average ratios\n",
    "    df[\"price_to_ma_5\"] = df[\"close\"] / df[\"ma_5\"]\n",
    "    df[\"price_to_ma_10\"] = df[\"close\"] / df[\"ma_10\"]\n",
    "    df[\"price_to_ma_20\"] = df[\"close\"] / df[\"ma_20\"]\n",
    "\n",
    "    # 2. Price-to-EMA ratios\n",
    "    df[\"price_to_ema_5\"] = df[\"close\"] / df[\"ema_5\"]\n",
    "    df[\"price_to_ema_10\"] = df[\"close\"] / df[\"ema_10\"]\n",
    "    df[\"price_to_ema_20\"] = df[\"close\"] / df[\"ema_20\"]\n",
    "\n",
    "    # 3. EMA-to-moving-average ratios\n",
    "    df[\"ema_to_ma_5\"] = df[\"ema_5\"] / df[\"ma_5\"]\n",
    "    df[\"ema_to_ma_10\"] = df[\"ema_10\"] / df[\"ma_10\"]\n",
    "    df[\"ema_to_ma_20\"] = df[\"ema_20\"] / df[\"ma_20\"]\n",
    "\n",
    "    # 4. EMA-to-EMA ratios\n",
    "    df[\"ema5_to_ema10\"] = df[\"ema_5\"] / df[\"ema_10\"]\n",
    "    df[\"ema5_to_ema20\"] = df[\"ema_5\"] / df[\"ema_20\"]\n",
    "    df[\"ema10_to_ema20\"] = df[\"ema_10\"] / df[\"ema_20\"]\n",
    "\n",
    "    # 5. Moving-average-to-moving-average ratios\n",
    "    df[\"ma5_to_ma10\"] = df[\"ma_5\"] / df[\"ma_10\"]\n",
    "    df[\"ma5_to_ma20\"] = df[\"ma_5\"] / df[\"ma_20\"]\n",
    "    df[\"ma10_to_ma20\"] = df[\"ma_10\"] / df[\"ma_20\"]\n",
    "\n",
    "    # 6. Price-to-Bollinger-Band ratios\n",
    "    df[\"price_to_upper_band\"] = df[\"close\"] / df[\"upper_band\"]\n",
    "    df[\"price_to_lower_band\"] = df[\"close\"] / df[\"lower_band\"]\n",
    "\n",
    "    # 7. Price-to-Keltner-Channel ratios\n",
    "    df[\"price_to_upper_keltner\"] = df[\"close\"] / df[\"upper_keltner\"]\n",
    "    df[\"price_to_lower_keltner\"] = df[\"close\"] / df[\"lower_keltner\"]\n",
    "\n",
    "    # 8. Price-to-previous-day-high ratio\n",
    "    df[\"price_to_prev_high\"] = df[\"close\"] / df[\"high\"].shift(1)\n",
    "\n",
    "    # 9. Price-to-previous-day-low ratio\n",
    "    df[\"price_to_prev_low\"] = df[\"close\"] / df[\"low\"].shift(1)\n",
    "\n",
    "    # 10. RSI-to-moving-average ratio\n",
    "    df[\"rsi_to_ma_5\"] = df[\"rsi\"] / df[\"ma_5\"]\n",
    "\n",
    "    ### CORRELATION ####\n",
    "\n",
    "    # Calculate some basic features first\n",
    "    returns = df[\"close\"].pct_change()\n",
    "    volume_change = df[\"volume\"].pct_change()\n",
    "\n",
    "    # 1. Correlation with returns and volume (short-term)\n",
    "    df[\"return_volume_corr_5\"] = returns.rolling(window=5).corr(df[\"volume\"])\n",
    "    df[\"return_volume_corr_10\"] = returns.rolling(window=10).corr(df[\"volume\"])\n",
    "    df[\"return_volume_corr_20\"] = returns.rolling(window=20).corr(df[\"volume\"])\n",
    "\n",
    "    # 2. Correlation with returns and volume (medium-term)\n",
    "    df[\"return_volume_corr_50\"] = returns.rolling(window=50).corr(df[\"volume\"])\n",
    "    df[\"return_volume_corr_100\"] = returns.rolling(window=100).corr(df[\"volume\"])\n",
    "\n",
    "    # 3. Correlation with price and volume\n",
    "    df[\"price_volume_corr_5\"] = df[\"close\"].rolling(window=5).corr(df[\"volume\"])\n",
    "    df[\"price_volume_corr_10\"] = df[\"close\"].rolling(window=10).corr(df[\"volume\"])\n",
    "    df[\"price_volume_corr_20\"] = df[\"close\"].rolling(window=20).corr(df[\"volume\"])\n",
    "\n",
    "    # 4. Correlation with price and volume (medium-term)\n",
    "    df[\"price_volume_corr_50\"] = df[\"close\"].rolling(window=50).corr(df[\"volume\"])\n",
    "    df[\"price_volume_corr_100\"] = df[\"close\"].rolling(window=100).corr(df[\"volume\"])\n",
    "\n",
    "    # 5. Price / volume\n",
    "    df[\"price_to_volume\"] = df[\"close\"] / df[\"volume\"]\n",
    "\n",
    "    # 6. Volume Relative Strength Index (VRSI)\n",
    "    delta_vol = df[\"volume\"].diff()\n",
    "    gain_vol = delta_vol.where(delta_vol > 0, 0)\n",
    "    loss_vol = -delta_vol.where(delta_vol < 0, 0)\n",
    "    avg_gain_vol = gain_vol.rolling(window=14).mean()\n",
    "    avg_loss_vol = loss_vol.rolling(window=14).mean()\n",
    "    rs_vol = avg_gain_vol / avg_loss_vol\n",
    "    df[\"vrsi\"] = 100 - 100 / (1 + rs_vol)\n",
    "\n",
    "    # 7. Change in volume\n",
    "    df[\"volume_change\"] = volume_change\n",
    "\n",
    "    # 8. Moving averages of volume\n",
    "    df[\"volume_ma_5\"] = df[\"volume\"].rolling(window=5).mean()\n",
    "    df[\"volume_ma_10\"] = df[\"volume\"].rolling(window=10).mean()\n",
    "    df[\"volume_ma_20\"] = df[\"volume\"].rolling(window=20).mean()\n",
    "\n",
    "    # 9. Standard deviation of volume\n",
    "    df[\"volume_std_5\"] = df[\"volume\"].rolling(window=5).std()\n",
    "    df[\"volume_std_10\"] = df[\"volume\"].rolling(window=10).std()\n",
    "    df[\"volume_std_20\"] = df[\"volume\"].rolling(window=20).std()\n",
    "\n",
    "    # 10. Ratio of volume to moving average volume\n",
    "    df[\"volume_to_ma_volume\"] = df[\"volume\"] / df[\"volume_ma_20\"]\n",
    "\n",
    "    ### EXTRA ###\n",
    "\n",
    "    # Calculate necessary base features\n",
    "    returns = df[\"close\"].pct_change()\n",
    "    delta = df[\"close\"].diff()\n",
    "\n",
    "    # close_change\n",
    "    df[\"close_change\"] = df[\"close\"].diff()\n",
    "\n",
    "    # high_pct\n",
    "    df[\"high_pct\"] = df[\"high\"].pct_change()\n",
    "\n",
    "    # close_change_roll5\n",
    "    df[\"close_change_roll5\"] = df[\"close_change\"].rolling(window=5).mean()\n",
    "\n",
    "    # RSI_14_roll5\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "    avg_gain = gain.rolling(window=14).mean()\n",
    "    avg_loss = loss.rolling(window=14).mean()\n",
    "    rs = avg_gain / avg_loss\n",
    "    rsi = 100 - 100 / (1 + rs)\n",
    "    df[\"RSI_14_roll5\"] = rsi.rolling(window=5).mean()\n",
    "\n",
    "    # ATR_14_roll5\n",
    "    true_range = pd.concat(\n",
    "        [\n",
    "            df[\"high\"] - df[\"low\"],\n",
    "            (df[\"high\"] - df[\"close\"].shift()).abs(),\n",
    "            (df[\"low\"] - df[\"close\"].shift()).abs(),\n",
    "        ],\n",
    "        axis=1,\n",
    "    ).max(axis=1)\n",
    "    df[\"ATR_14_roll5\"] = true_range.rolling(window=14).mean().rolling(window=5).mean()\n",
    "\n",
    "    # volume_roll5\n",
    "    df[\"volume_roll5\"] = df[\"volume\"].rolling(window=5).mean()\n",
    "\n",
    "    # high_pct_roll5\n",
    "    df[\"high_pct_roll5\"] = df[\"high_pct\"].rolling(window=5).mean()\n",
    "\n",
    "    # volatility_5\n",
    "    df[\"volatility_5\"] = df[\"close\"].rolling(window=5).std()\n",
    "\n",
    "    # price_ema5\n",
    "    df[\"price_ema5\"] = df[\"close\"].ewm(span=5).mean()\n",
    "\n",
    "    # volume_ema5\n",
    "    df[\"volume_ema5\"] = df[\"volume\"].ewm(span=5).mean()\n",
    "\n",
    "    # price_to_ema5\n",
    "    df[\"price_to_ema5\"] = df[\"close\"] / df[\"price_ema5\"]\n",
    "\n",
    "    # volume_change_roll5\n",
    "    df[\"volume_change_roll5\"] = volume_change.rolling(window=5).mean()\n",
    "\n",
    "    # avg_vol_last_100\n",
    "    df[\"avg_vol_last_100\"] = df[\"volume\"].rolling(window=100).mean()\n",
    "\n",
    "    # turnover\n",
    "    df[\"turnover\"] = df[\"volume\"] * df[\"close\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def timeseries_cv_score(X, y, n_splits):\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    f1_scores = []\n",
    "    auc_scores = []  # list to store ROC AUC scores for each split\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Define LSTM model\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "        model.add(Dense(1, activation=\"sigmoid\"))  # because of binary classification\n",
    "\n",
    "        model.compile(\n",
    "            loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train, epochs=10, verbose=0)\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred = model.predict(X_test).ravel()\n",
    "\n",
    "        # Calculate F1 score of the model on the test set\n",
    "        f1 = f1_score(y_test, (y_pred > 0.5).astype(\"int32\"))\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "        # Calculate ROC AUC score of the model on the test set\n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "        auc_scores.append(auc)\n",
    "\n",
    "    return np.mean(f1_scores), np.mean(auc_scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display options to show all rows and columns\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# Prepare TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "# Load the data\n",
    "data_path = \"../../../data/kc/btc/raw/kc_btc_15min.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['open', 'close', 'high', 'low', 'volume', 'color', 'time',\n",
      "       'color_change'],\n",
      "      dtype='object')\n",
      "[+] Strategy: All\n",
      "[i] Indicator arguments: {'fast': 10, 'slow': 50, 'append': True}\n",
      "[i] Excluded[12]: above, above_value, below, below_value, cross, cross_value, long_run, short_run, td_seq, tsignals, vp, xsignals\n",
      "[i] Multiprocessing 131 indicators with 3 chunks and 12/12 cpus.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "131it [00:02, 51.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Total indicators: 131\n",
      "[i] Columns added: 278\n",
      "[i] Last Run: Tuesday June 20, 2023, NYSE: 19:12:40, Local: 23:12:40 Pacific Daylight Time, Day 171/365 (47.00%)\n",
      "Index(['open', 'close', 'high', 'low', 'volume', 'color', 'color_change',\n",
      "       'time_unix', 'ABER_ZG_5_15', 'ABER_SG_5_15',\n",
      "       ...\n",
      "       'HA_ema15', 'HA_pct_diff_ema5_15', 'HA_rsi', 'HA_macd', 'HA_macds',\n",
      "       'HA_macdh', 'HA_cci', 'HA_atr', 'HA_ha_close_bbp50_std', 'HA_mfi'],\n",
      "      dtype='object', length=311)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Argument 'real' has incorrect type (expected numpy.ndarray, got tuple)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[465], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mmerge(kagi_df, left_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, right_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     30\u001b[0m tlb_df \u001b[39m=\u001b[39m tlb(df)\n\u001b[1;32m---> 31\u001b[0m tlb_df \u001b[39m=\u001b[39m add_tlb_ft(tlb_df)\n\u001b[0;32m     32\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mmerge(tlb_df, left_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, right_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     33\u001b[0m \u001b[39m# pnf_df = point_and_figure(df, box_size=1, reversal=3)\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[39m# pnf_df = add_point_and_figure_features(pnf_df)\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39m# df = df.merge(pnf_df, on=\"time\", how=\"outer\")\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[39m# tlb_df = three_line_break(df, reversal=3)\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[39m# tlb_df = add_three_line_break_features(tlb_df)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[463], line 435\u001b[0m, in \u001b[0;36madd_tlb_ft\u001b[1;34m(tlb_df)\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[39mfor\u001b[39;00m fn, tp \u001b[39min\u001b[39;00m (\n\u001b[0;32m    421\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39mSMA\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m5\u001b[39m),\n\u001b[0;32m    422\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39mEMA\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m5\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    432\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39mROC\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m10\u001b[39m),\n\u001b[0;32m    433\u001b[0m ):\n\u001b[0;32m    434\u001b[0m     \u001b[39mif\u001b[39;00m fn \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mSMA\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mEMA\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mWMA\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m--> 435\u001b[0m         ft[fn] \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(talib, fn)(c, tp)\n\u001b[0;32m    436\u001b[0m     \u001b[39melif\u001b[39;00m fn \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMACD\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    437\u001b[0m         ft[\u001b[39m\"\u001b[39m\u001b[39mmacd\u001b[39m\u001b[39m\"\u001b[39m], ft[\u001b[39m\"\u001b[39m\u001b[39mmacdsignal\u001b[39m\u001b[39m\"\u001b[39m], ft[\u001b[39m\"\u001b[39m\u001b[39mmacdhist\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m talib\u001b[39m.\u001b[39mMACD(c, \u001b[39m12\u001b[39m, \u001b[39m26\u001b[39m, \u001b[39m9\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jnorm\\Projects\\websocket_trading\\.venv\\lib\\site-packages\\talib\\__init__.py:64\u001b[0m, in \u001b[0;36m_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     61\u001b[0m     _args \u001b[39m=\u001b[39m args\n\u001b[0;32m     62\u001b[0m     _kwds \u001b[39m=\u001b[39m kwds\n\u001b[1;32m---> 64\u001b[0m result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39m_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_kwds)\n\u001b[0;32m     66\u001b[0m \u001b[39m# check to see if we got a streaming result\u001b[39;00m\n\u001b[0;32m     67\u001b[0m first_result \u001b[39m=\u001b[39m result[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, \u001b[39mtuple\u001b[39m) \u001b[39melse\u001b[39;00m result\n",
      "\u001b[1;31mTypeError\u001b[0m: Argument 'real' has incorrect type (expected numpy.ndarray, got tuple)"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the data\n",
    "df = load_data(data_path)\n",
    "df = preprocess_data(df)\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "# Timestamp conversion and index setting\n",
    "df[\"time_unix\"] = df[\"time\"]\n",
    "df[\"time\"] = pd.to_datetime(df[\"time\"], unit=\"s\")  # Assuming 'time' is in seconds\n",
    "df.set_index(\"time\", inplace=True)\n",
    "df = df.loc[~df.index.duplicated(keep=\"first\")]\n",
    "\n",
    "# Technical Analysis features\n",
    "# df.ta.strategy(\"all\")\n",
    "\n",
    "# Check your results and exclude as necessary.\n",
    "df.ta.strategy(fast=10, slow=50, verbose=True)\n",
    "\n",
    "# Chart Transformation features\n",
    "df = add_heiken_ashi_features(df)\n",
    "print(df.columns)\n",
    "\n",
    "brick_size = 1\n",
    "renko_df = compute_renko(df, brick_size)\n",
    "df = add_renko_features(df, renko_df)\n",
    "df = df.merge(renko_df, left_on=\"time\", right_on=\"time\")\n",
    "kagi_df = kagi(df)\n",
    "kagi_df = add_kagi_features(df, kagi_df)\n",
    "df = df.merge(kagi_df, left_index=True, right_index=True)\n",
    "tlb_df = tlb(df)\n",
    "tlb_df = add_tlb_ft(tlb_df)\n",
    "df = df.merge(tlb_df, left_index=True, right_index=True)\n",
    "# pnf_df = point_and_figure(df, box_size=1, reversal=3)\n",
    "# pnf_df = add_point_and_figure_features(pnf_df)\n",
    "# df = df.merge(pnf_df, on=\"time\", how=\"outer\")\n",
    "# tlb_df = three_line_break(df, reversal=3)\n",
    "# tlb_df = add_three_line_break_features(tlb_df)\n",
    "\n",
    "df.tail()\n",
    "\n",
    "# # Additional features\n",
    "# df = create_features(df)\n",
    "\n",
    "# # Now extract additional date information from the original dataframe\n",
    "# df[\"minute\"] = df.index.minute\n",
    "# df[\"hour\"] = df.index.hour\n",
    "# df[\"day\"] = df.index.day\n",
    "# df[\"month\"] = df.index.month\n",
    "\n",
    "# # Sanity check. Make sure all the columns and types\n",
    "# # print(df.columns)\n",
    "\n",
    "# # Forward Fill\n",
    "# df.ffill(inplace=True)\n",
    "\n",
    "# # Backward Fill\n",
    "# df.bfill(inplace=True)\n",
    "\n",
    "# # # Finding problem features for standard scalar\n",
    "# # non_num_features = df.select_dtypes(exclude=[\"int32\", \"int64\", \"float32\", \"float64\"])\n",
    "# # print(\"Fix these features:\\n\")\n",
    "# # for col, dtype in non_num_features.dtypes.items():\n",
    "# #     print(f\"{col}: {dtype}\")\n",
    "\n",
    "\n",
    "# # Select numeric columns which need to be scaled\n",
    "# do_not_scale_columns = [\n",
    "#     \"time_unix\",\n",
    "#     \"minute\",\n",
    "#     \"hour\",\n",
    "#     \"day\",\n",
    "#     \"month\",\n",
    "# ]\n",
    "# scaler = StandardScaler()\n",
    "# for col in df.columns:\n",
    "#     if col not in do_not_scale_columns:\n",
    "#         df[col] = scaler.fit_transform(df[[col]])\n",
    "\n",
    "\n",
    "# X = df.drop(\"color_change\", axis=1)\n",
    "# y = df[\"color_change\"]\n",
    "\n",
    "# df.tail()\n",
    "# duplicate features\n",
    "# duplicated_features = df.columns.duplicated()\n",
    "# print(\"Duplicate Features: \", df.columns[duplicated_features])\n",
    "# Total features\n",
    "# print(\"Total features in DataFrame: \", df.shape[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Feature Selection Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HA_body: 294.38880119737655\n",
      "THERMOs_20_2_0.5: 273.60362108048645\n",
      "THERMO_20_2_0.5: 270.249417080584\n",
      "THERMOl_20_2_0.5: 157.06919674247334\n",
      "volume_to_ma_volume: 95.47666501167771\n",
      "volume: 91.47185887138413\n",
      "HA_high_low: 90.77134390075592\n",
      "PVOL: 90.50536446119777\n",
      "turnover: 90.50536446119777\n",
      "BBB_5_2.0: 79.13500197982869\n",
      "std_5: 77.08391210633341\n",
      "volatility_5: 77.08391210633341\n",
      "ER_10: 76.49120671158205\n",
      "vrsi: 66.81200791486042\n",
      "volume_change: 54.94609293559068\n",
      "PSARr_0.02_0.2: 42.35299874492656\n",
      "TRUERANGE_1: 40.93139905386556\n",
      "PVOh_10_50_9: 40.746005572468654\n",
      "PDIST: 38.215663834041884\n",
      "PVOh_12_26_9: 36.55651784395762\n",
      "high_pct: 32.9043488025379\n",
      "volume_ema5: 29.801691211064494\n",
      "KURT_30: 27.621189680766168\n",
      "PVO_10_50_9: 24.851073575058958\n",
      "volume_std_5: 23.66638808822487\n",
      "PVO_12_26_9: 23.58845909024736\n",
      "PVR: 22.44330032229265\n",
      "volume_change_roll5: 18.194421025682455\n",
      "volume_ma_5: 16.86198277783865\n",
      "volume_roll5: 16.86198277783865\n",
      "std_10: 15.569841528761476\n",
      "VHF_28: 14.526500737766861\n",
      "DMN_14: 11.907639542415312\n",
      "THERMOma_20_2_0.5: 11.431096476076542\n",
      "AROONU_14: 9.647634376719152\n",
      "volume_std_10: 9.332066603447812\n",
      "ema_to_ma_5: 8.577588197820054\n",
      "lag_return_4: 8.248260893494166\n",
      "DMP_14: 8.054813920069284\n",
      "BULLP_13: 7.378024653948846\n",
      "price_to_volume: 6.010234479052775\n",
      "lag_return_1: 5.639492027031972\n",
      "PVOs_10_50_9: 5.2998894275357\n",
      "PVOs_12_26_9: 5.171253620181493\n",
      "HA_close_pct_change: 5.015304037336622\n",
      "volume_ma_10: 4.830696126825448\n",
      "HA_close_change: 4.445553507749721\n",
      "STCstoch_10_10_50_0.5: 4.315899614260849\n",
      "SQZPRO_ON_NARROW: 4.085720304893971\n",
      "diff_2: 3.864596483998754\n",
      "STC_10_12_26_0.5: 3.746979700686434\n",
      "AROOND_14: 3.665382673985498\n",
      "volume_std_20: 3.585932945265056\n",
      "BEARP_13: 3.566753157134531\n",
      "HA_close_open: 3.4654681897754243\n",
      "price_to_ma_5: 3.0899565042346646\n",
      "VTXM_14: 3.0764016621101753\n",
      "SQZPRO_OFF: 2.91723770857903\n",
      "high_pct_roll5: 2.7304500358184667\n",
      "SQZPRO_ON_WIDE: 2.7069355978806513\n",
      "diff_4: 2.5363744044996435\n",
      "price_to_prev_low: 2.394956908417957\n",
      "AMATe_LR_10_50_2: 2.199346082870091\n",
      "diff_3: 2.1346465726049617\n",
      "STC_10_10_50_0.5: 2.0429994881181903\n",
      "volume_ma_20: 1.8713072538971363\n",
      "AMATe_SR_10_50_2: 1.8416017320514624\n",
      "return_volume_corr_100: 1.841581295410031\n",
      "HA_atr: 1.7884082115678066\n",
      "price_to_prev_high: 1.7282642339630876\n",
      "return_volume_corr_5: 1.7050914807576631\n",
      "STCstoch_10_12_26_0.5: 1.6501504380193088\n",
      "SQZ_OFF: 1.568308465351751\n",
      "hour: 1.4507111484661783\n",
      "SQZ_ON: 1.4145150511218825\n",
      "SQZPRO_ON_NORMAL: 1.4145150511218825\n",
      "KVO_10_50_13: 1.4051592789503258\n",
      "price_to_ema_5: 1.377552754252941\n",
      "price_to_ema5: 1.377552754252941\n",
      "MASSI_9_25: 1.3512817636654129\n",
      "HA_cci: 1.1988699343068667\n",
      "ma5_to_ma10: 1.1831801045483321\n",
      "cci: 1.16602374937141\n",
      "MASSI_10_50: 1.151517807386876\n",
      "AMATe_SR_8_21_2: 1.065560252719997\n",
      "CDL_3BLACKCROWS: nan\n",
      "CDL_3INSIDE: 1.8612268392895508\n",
      "CDL_3OUTSIDE: 1.3018667198128546\n",
      "BOP: 1.0212877780379066\n",
      "NATR_14: 0.9900225172328019\n",
      "DPO_20: 0.913632317779595\n",
      "CTI_12: 0.9019710189226346\n",
      "INERTIA_20_14: 0.869768785817959\n",
      "price_volume_corr_10: 0.8493071058866826\n",
      "atr: 0.8492170804294696\n",
      "atr_14: 0.8492170804294696\n",
      "ema_to_ma_20: 0.82673349747438\n",
      "return_volume_corr_10: 0.818142378277507\n",
      "price_volume_corr_100: 0.8052933993368997\n",
      "DEC_1: 0.7404420400153137\n",
      "EOM_14_100000000: 0.732729283748669\n",
      "ma5_to_ma20: 0.7199724609836334\n",
      "price_volume_corr_20: 0.6731098900618664\n",
      "rsi_to_ma_5: 0.653592750667158\n",
      "FISHERTs_9_1: 0.6434352645833736\n",
      "return_volume_corr_50: 0.6351007386865389\n",
      "ICS_26: 0.6289336869994196\n",
      "SKEW_30: 0.6144106404325407\n",
      "BBL_5_2.0: 0.607596603573661\n",
      "lag_return_5: 0.5600648614434983\n",
      "diff_19: 0.5539139481804698\n",
      "AROONOSC_14: 0.5401811334805464\n",
      "PPOh_12_26_9: 0.5192660635316891\n",
      "hist_volatility_10: 0.5085117230955355\n",
      "FISHERT_9_1: 0.5016924304045844\n",
      "D_9_3: 0.4962376538017703\n",
      "STOCHk_14_3_3: 0.49592461497956347\n",
      "price_to_ema_10: 0.48761124360247143\n",
      "STOCHRSIk_14_14_3_3: 0.4854027105614965\n",
      "OBVe_10: 0.48463957597663054\n",
      "TTM_TRND_6: 0.48045055648610074\n",
      "OBVe_12: 0.47985708205281685\n",
      "lag_rsi_1: 0.47237791599791024\n",
      "ZS_30: 0.4642915551052402\n",
      "RSX_14: 0.46092290893226673\n",
      "price_to_upper_band: 0.4527669061903479\n",
      "OBVe_50: 0.4467651634997706\n",
      "color: 0.4452904087414623\n",
      "SQZ_20_2.0_20_1.5: 0.44524693869746956\n",
      "SQZPRO_20_2.0_20_2_1.5_1: 0.44524693869746956\n",
      "cmf: 0.4293228323030551\n",
      "return_volume_corr_20: 0.4241714149905241\n",
      "HA_macdh: 0.41789121961698156\n",
      "obv: 0.41619803294576446\n",
      "OBV: 0.41619803294575647\n",
      "price_to_lower_band: 0.4133573851480212\n",
      "HA_low: 0.41157582004493265\n",
      "HA_HA_low: 0.41157582004493265\n",
      "PGO_14: 0.40147070708253263\n",
      "rsi: 0.3939498206180177\n",
      "UO_10_14_50: 0.3877931332026304\n",
      "PCTRET_1: 0.3760842272692227\n",
      "pct_change: 0.3760842272692227\n",
      "VTXP_14: 0.3718789407427505\n",
      "INC_1: 0.3697540671424167\n",
      "RVI_14: 0.36917807859842566\n",
      "SQZ_NO: 0.36548037173724895\n",
      "SQZPRO_NO: 0.36548037173724895\n",
      "STOCHd_14_3_3: 0.36325310364998414\n",
      "OBV_max_2: 0.34522088140367935\n",
      "EFI_13: 0.3388434075397863\n",
      "PVT: 0.3385677634660697\n",
      "LOGRET_1: 0.33640524209528777\n",
      "price_to_ma_10: 0.335786474842513\n",
      "op_cl_diff: 0.3337844168375097\n",
      "SLOPE_1: 0.32735352071386836\n",
      "price_diff: 0.32735352071386836\n",
      "diff_1: 0.32735352071386836\n",
      "close_change: 0.32735352071386836\n",
      "EBSW_40_10: 0.3250105615056873\n",
      "lag_low_3: 0.3186086953790712\n",
      "KVO_34_55_13: 0.3152043355059089\n",
      "lag_low_2: 0.3132680681500318\n",
      "DCL_20_20: 0.3073676262607635\n",
      "SMI_5_20_5: 0.3062319889669111\n",
      "price_to_lower_keltner: 0.30391556059700225\n",
      "COPC_11_14_10: 0.30365681705376374\n",
      "ma10_to_ma20: 0.3016530274931625\n",
      "K_9_3: 0.2991301565126815\n",
      "ALMA_10_6.0_0.85: 0.2976418393705159\n",
      "MFI_14: 0.2903606376049222\n",
      "lag_return_3: 0.28909675940258095\n",
      "williams_r: 0.2875289375338874\n",
      "WILLR_14: 0.28752893753388653\n",
      "lag_close_4: 0.2853261792334404\n",
      "KCLe_20_2: 0.28059033311083137\n",
      "lower_band: 0.28029411625507383\n",
      "QQEs_14_5_4.236: 0.2798214324648871\n",
      "lag_close_2: 0.27604721791418274\n",
      "ABER_XG_5_15: 0.27597218670444484\n",
      "lag_close_3: 0.26991578403063166\n",
      "HA_vwap: 0.2644580922425665\n",
      "HMA_10: 0.2586042476561671\n",
      "HA_open: 0.25728597723791413\n",
      "HA_HA_open: 0.25728597723791413\n",
      "lag_low_1: 0.25652285361308214\n",
      "COPC_10_50_10: 0.2563527491686804\n",
      "lower_keltner: 0.2553090909776037\n",
      "ABER_ZG_5_15: 0.25523795909352676\n",
      "HA_sma5: 0.2552084908334155\n",
      "lag_high_3: 0.25468552679387685\n",
      "ma_5: 0.252874020315831\n",
      "HA_close_lag1: 0.24934723453273402\n",
      "diff_18: 0.24927440045739702\n",
      "SSF_10_2: 0.24887204687922432\n",
      "diff_20: 0.2461491719651466\n",
      "SUPERTs_7_3.0: 0.24469372305941642\n",
      "ACCBL_20: 0.2443654436371886\n",
      "LR_14: 0.2439944080342776\n",
      "PWMA_10: 0.2436536677703752\n",
      "HWU: 0.2425935357108789\n",
      "ISA_9: 0.24210099427013804\n",
      "lag_high_1: 0.2420899641770397\n",
      "ZL_EMA_10: 0.2410963177923508\n",
      "TEMA_10: 0.24103480783184564\n",
      "diff_34: 0.240723312119853\n",
      "DEMA_10: 0.24017438743976866\n",
      "HILOl_13_21: 0.23939405497377997\n",
      "HA_ema5: 0.23893938271081233\n",
      "lag_high_2: 0.23893221210186127\n",
      "WMA_10: 0.2374171919991403\n",
      "SWMA_10: 0.23715162869341375\n",
      "TRIMA_10: 0.23715162869333267\n",
      "RSI_14_roll5: 0.23597471527212713\n",
      "ENTP_10: 0.2349143659154329\n",
      "ema_5: 0.23402378727331652\n",
      "price_ema5: 0.23402378727331652\n",
      "PVI_1: 0.2339474952243906\n",
      "MIDPRICE_2: 0.23342734215505057\n",
      "FWMA_10: 0.23318260379016512\n",
      "HA_ema10: 0.23297651633631025\n",
      "VWAP_D: 0.2319226167935411\n",
      "ema_10: 0.23085654414293352\n",
      "EMA_10: 0.2307692655844107\n",
      "JMA_7_0: 0.23012362454757504\n",
      "ma_10: 0.22969358317336333\n",
      "SMA_10: 0.22969358317331448\n",
      "MACDh_10_50_9: 0.22864474421890632\n",
      "HA_mfi: 0.22855515216659897\n",
      "HA_ema15: 0.22759787654410063\n",
      "STOCHRSId_14_14_3_3: 0.2267287192831018\n",
      "PSARaf_0.02_0.2: 0.22670920822068988\n",
      "MCGD_10: 0.2260381938472871\n",
      "HWM: 0.22582726703895037\n",
      "HWMA_0.2_0.1_0.1: 0.22582726703895037\n",
      "lag_close_1: 0.22460743213797515\n",
      "RMA_10: 0.22430764509651174\n",
      "T3_10_0.7: 0.2240555734826596\n",
      "SINWMA_14: 0.22402609735975754\n",
      "ema_20: 0.22390921021779067\n",
      "RSI_14: 0.22375497885465578\n",
      "KCBe_20_2: 0.22368722204003585\n",
      "SMIs_5_20_5: 0.22360033956306885\n",
      "lag_close_5: 0.22303450661482463\n",
      "PSARl_0.02_0.2: 0.22219501286839544\n",
      "VWMA_10: 0.22181244506524292\n",
      "MIDPOINT_2: 0.21849739488361591\n",
      "IKS_26: 0.21786505062945064\n",
      "ITS_9: 0.21588446912089537\n",
      "HA_close: 0.2144764042800686\n",
      "OHLC4: 0.2144764042800686\n",
      "HA_HA_close: 0.2144764042800686\n",
      "lag_close_10: 0.21425131559041172\n",
      "close: 0.21240017717435639\n",
      "WCP: 0.21143096575769854\n",
      "HLC3: 0.21110515368553742\n",
      "ma_20: 0.21106708553984113\n",
      "HL2: 0.2104494594499357\n",
      "HWL: 0.20896080831509609\n",
      "ISB_26: 0.20779107452575354\n",
      "lag_close_8: 0.20534161047331526\n",
      "lag_close_9: 0.20316089507324708\n",
      "lag_close_6: 0.20276567203062537\n",
      "lag_close_7: 0.20254734695509038\n",
      "diff_31: 0.2015826581070679\n",
      "ADOSC_10_50: 0.19981485722060213\n",
      "DCM_20_20: 0.1968903323046093\n",
      "MEDIAN_30: 0.1959412274044063\n",
      "QTL_30_0.5: 0.1959412274044063\n",
      "MACDh_12_26_9: 0.19002229540118587\n",
      "diff_29: 0.18874317801225468\n",
      "diff_30: 0.18718735760431876\n",
      "HA_rsi: 0.1816316992595843\n",
      "SMIo_5_20_5: 0.18084156493693376\n",
      "HILO_13_21: 0.1793770892190575\n",
      "HILOs_13_21: 0.1792336383796434\n",
      "price_volume_corr_5: 0.178507766180824\n",
      "ACCBU_20: 0.17777630698272712\n",
      "QQE_14_5_4.236_RSIMA: 0.17653866120786696\n",
      "KCUe_20_2: 0.17473555332343343\n",
      "LDECAY_5: 0.1730939854227007\n",
      "upper_keltner: 0.17202275166600614\n",
      "minute: 0.16752417670243291\n",
      "RVGI_14_4: 0.1640087164871984\n",
      "hist_volatility_30: 0.1590990351017002\n",
      "SUPERT_7_3.0: 0.15872629500266536\n",
      "KAMA_10_2_30: 0.1586883027437258\n",
      "price_to_upper_keltner: 0.15619493976962798\n",
      "upper_band: 0.15235468864722626\n",
      "SUPERTl_7_3.0: 0.13763990183017616\n",
      "PSARs_0.02_0.2: 0.13364749455035213\n",
      "HA_pct_diff_ema5_15: 0.13357972232363033\n",
      "price_to_ema_20: 0.13170205225608533\n",
      "diff_15: 0.11803790688971938\n",
      "DCU_20_20: 0.11329613805806595\n",
      "TSI_13_25_13: 0.10677255586452578\n",
      "diff_14: 0.10660086206228594\n",
      "QQE_14_5_4.236: 0.10551338323569076\n",
      "hist_volatility_20: 0.10523603477323694\n",
      "HA_macd: 0.10262871758393324\n",
      "UI_14: 0.10043794213277109\n",
      "HA_high: 0.09984625612765054\n",
      "HA_HA_high: 0.09984625612765054\n",
      "PPO_12_26_9: 0.09930253564655514\n",
      "NVI_1: 0.08968907301469257\n",
      "UO_7_14_28: 0.07930471027837822\n",
      "STCmacd_10_12_26_0.5: 0.0747667078009574\n",
      "ema10_to_ema20: 0.07343668085192886\n",
      "MACD_12_26_9: 0.07335279734338172\n",
      "lag_return_2: 0.07203620878438803\n",
      "STDEV_30: 0.07139033361682348\n",
      "TSIs_13_25_13: 0.06931306170737979\n",
      "QQEl_14_5_4.236: 0.06597460315259669\n",
      "J_9_3: 0.06549073565987854\n",
      "diff_11: 0.05493467935517495\n",
      "roc_5: 0.05315982246542414\n",
      "CDL_3LINESTRIKE: 0.05160407317821078\n",
      "close_change_roll5: 0.04995432183763382\n",
      "diff_5: 0.049954321837633466\n",
      "ppo: 0.048581933257917306\n",
      "ema5_to_ema20: 0.0469869669336164\n",
      "TSIs_10_50_13: 0.04643637140208808\n",
      "diff_32: 0.04615556767849407\n",
      "diff_33: 0.04504158623239408\n",
      "TSI_10_50_13: 0.039587258156405576\n",
      "SMI_10_50_5: 0.039587258156404626\n",
      "price_volume_corr_50: 0.03922309655011818\n",
      "PPOh_10_50_9: 0.036563294332736286\n",
      "diff_25: 0.03582136186509547\n",
      "SMIs_10_50_5: 0.034864173798330136\n",
      "diff_6: 0.03398524503706782\n",
      "BBP_5_2.0: 0.031242153264314617\n",
      "CDL_3STARSINSOUTH: nan\n",
      "CDL_3WHITESOLDIERS: 7.990304036217392\n",
      "CCI_14_0.015: 1.4807648702844043\n",
      "CDL_ABANDONEDBABY: nan\n",
      "CDL_ADVANCEBLOCK: 107.44435266116137\n",
      "CDL_BELTHOLD: 1.3610286991597027\n",
      "AMATe_LR_8_21_2: 1.2859566508917912\n",
      "CDL_2CROWS: 1.1396534093077633\n",
      "ATRr_14: 0.9104746081814175\n",
      "BR_26: 0.78071578473594\n",
      "ABER_ATR_5_15: 0.7788502422916421\n",
      "AR_26: 0.6985757210176851\n",
      "ADOSC_3_10: 0.6883592208277559\n",
      "OBV_min_2: 0.5591854195833902\n",
      "OBVe_4: 0.47717458404859814\n",
      "low: 0.3040970101290234\n",
      "AO_5_34: 0.28576718207771223\n",
      "BBM_5_2.0: 0.2528740203158781\n",
      "ABER_SG_5_15: 0.23539790386047868\n",
      "open: 0.22470195021284925\n",
      "ACCBM_20: 0.21106708553985348\n",
      "AD: 0.20718604906112625\n",
      "APO_12_26: 0.17109364723535517\n",
      "ADX_14: 0.16572563017629643\n",
      "high: 0.13458278958403122\n",
      "AOBV_SR_2: 0.05401469430240557\n",
      "BBU_5_2.0: 0.05318458418522088\n",
      "diff_7: 0.030238154488210205\n",
      "VIDYA_14: 0.02980464608063244\n",
      "HA_direction: 0.028836190849313017\n",
      "KAMA_10_10_50: 0.028494064829579037\n",
      "avg_vol_last_100: 0.027001579429387055\n",
      "ema_to_ma_10: 0.022423345134501654\n",
      "TOS_STDEVALL_L_2: 0.021409582359967518\n",
      "TOS_STDEVALL_U_2: 0.021409582359967518\n",
      "time_unix: 0.021409582359966955\n",
      "TOS_STDEVALL_LR: 0.021409582359966334\n",
      "TOS_STDEVALL_U_1: 0.021409582359966334\n",
      "TOS_STDEVALL_L_3: 0.021409582359966334\n",
      "TOS_STDEVALL_L_1: 0.02140958235996633\n",
      "TOS_STDEVALL_U_3: 0.021409582359965804\n",
      "diff_27: 0.020348682632358634\n",
      "diff_9: 0.020019414427336964\n",
      "diff_26: 0.019379688563621638\n",
      "HA_macds: 0.019330150862616403\n",
      "ema5_to_ema10: 0.018704375038241617\n",
      "BIAS_SMA_26: 0.018483189328263955\n",
      "STCmacd_10_10_50_0.5: 0.0181585680025451\n",
      "MACD_10_50_9: 0.017991883295607317\n",
      "day: 0.017927840481702602\n",
      "price_to_ma_20: 0.016804579781403987\n",
      "diff_12: 0.016601385964315016\n",
      "diff_17: 0.01622242669896572\n",
      "TRIXs_30_9: 0.015886294946637156\n",
      "roc_10: 0.01558090694239157\n",
      "VAR_30: 0.015064964923564197\n",
      "AO_10_50: 0.014536334542925052\n",
      "ATR_14_roll5: 0.013282295104292257\n",
      "diff_8: 0.012714420285134788\n",
      "PPO_10_50_9: 0.012429246692723708\n",
      "SMIo_10_50_5: 0.012148236745592556\n",
      "SUPERTd_7_3.0: 0.011976944016314167\n",
      "KVOs_10_50_13: 0.01190176308263763\n",
      "APO_10_50: 0.01165400826263904\n",
      "AOBV_LR_2: 0.011190190270833062\n",
      "CDL_BREAKAWAY: nan\n",
      "diff_13: 0.010223440578305251\n",
      "diff_28: 0.009671020065418217\n",
      "diff_22: 0.007793254607581237\n",
      "TRIX_30_9: 0.005644033875035865\n",
      "CDL_CLOSINGMARUBOZU: 0.005638399724118935\n",
      "CDL_CONCEALBABYSWALL: nan\n",
      "CDL_COUNTERATTACK: nan\n",
      "CDL_INNECK: nan\n",
      "CDL_KICKING: nan\n",
      "CDL_KICKINGBYLENGTH: nan\n",
      "CDL_LADDERBOTTOM: nan\n",
      "CDL_MATCHINGLOW: 158.30422655845786\n",
      "CDL_INVERTEDHAMMER: 35.61294885521385\n",
      "CDL_MATHOLD: nan\n",
      "CDL_ONNECK: nan\n",
      "CDL_SHOOTINGSTAR: 43.547263409478695\n",
      "CDL_STALLEDPATTERN: 24.060499073288227\n",
      "CDL_EVENINGSTAR: 23.83585607940599\n",
      "CDL_IDENTICAL3CROWS: 22.908645526841614\n",
      "CDL_HANGINGMAN: 19.79177041285269\n",
      "CDL_MORNINGSTAR: 14.08862384118259\n",
      "CDL_SHORTLINE: 10.69145524005598\n",
      "CDL_GAPSIDESIDEWHITE: 7.990304036217483\n",
      "CDL_TASUKIGAP: nan\n",
      "CDL_THRUSTING: 7.9119018078699375\n",
      "CDL_EVENINGDOJISTAR: 5.270910091736318\n",
      "CDL_HOMINGPIGEON: 4.562247929262991\n",
      "CDL_STICKSANDWICH: 4.391400723584732\n",
      "CDL_UNIQUE3RIVER: nan\n",
      "CDL_UPSIDEGAP2CROWS: nan\n",
      "CHOP_14_1_100: 42.99626362548692\n",
      "CFO_9: 4.291754661611884\n",
      "CDL_DOJISTAR: 4.2128010470306485\n",
      "high_Z_30_1: 3.6221865398988777\n",
      "CDL_MORNINGDOJISTAR: 2.633612070312061\n",
      "CDL_DARKCLOUDCOVER: 2.63361207031197\n",
      "CDL_PIERCING: 1.7553322118606516\n",
      "CDL_LONGLEGGEDDOJI: 1.6131000139836142\n",
      "CDL_DOJI_10_0.1: 1.547491908620828\n",
      "CDL_HARAMI: 1.5255612866133963\n",
      "CDL_MARUBOZU: 1.4674750469244995\n",
      "CDL_RICKSHAWMAN: 1.2286427892812306\n",
      "CDL_TRISTAR: 1.139653409308029\n",
      "open_Z_30_1: 1.0551758077533409\n",
      "CDL_SEPARATINGLINES: 1.036939737816805\n",
      "CDL_INSIDE: 0.8126768379482187\n",
      "CDL_XSIDEGAP3METHODS: 0.7896970561010472\n",
      "CDL_HIKKAKE: 0.7653718755119724\n",
      "CDL_ENGULFING: 0.7591024834305138\n",
      "CDL_SPINNINGTOP: 0.6336019513179354\n",
      "CDL_HARAMICROSS: 0.5016983586920977\n",
      "close_Z_30_1: 0.4642915551052402\n",
      "CMF_20: 0.4293228323019172\n",
      "CG_10: 0.35908551156533064\n",
      "CKSPs_10_3_20: 0.25488893576402266\n",
      "CMO_14: 0.2237549788546555\n",
      "CDL_HIKKAKEMOD: 0.20557545589916404\n",
      "CKSPl_10_3_20: 0.15427594564634975\n",
      "CDL_HIGHWAVE: 0.14462343558540405\n",
      "CDL_TAKURI: 0.09367045336632934\n",
      "CDL_LONGLINE: 0.05485723620651173\n",
      "CDL_HAMMER: 0.032820746075387916\n",
      "CDL_GRAVESTONEDOJI: 0.031159971273315074\n",
      "KVOs_34_55_13: 0.030774165403624903\n",
      "low_Z_30_1: 0.028739115639211707\n",
      "PSL_12: 0.026164247121770175\n",
      "MAD_30: 0.02399004243732749\n",
      "MACDs_12_26_9: 0.022960893682645717\n",
      "ROC_10: 0.015580906942391826\n",
      "KSTs_9: 0.015146090875923073\n",
      "RVGIs_14_4: 0.010973720806039007\n",
      "CDL_DRAGONFLYDOJI: 0.008800903037532783\n",
      "HA_ha_close_bbp50_std: 0.005036015953621532\n",
      "diff_24: 0.00495617806750573\n",
      "month: 0.0038493007672137413\n",
      "diff_16: 0.0035312850720857266\n",
      "PPOs_10_50_9: 0.0033545912880140008\n",
      "diff_23: 0.0017078029678881791\n",
      "PPOs_12_26_9: 0.0013660353287929666\n",
      "MOM_10: 0.0010492508181889793\n",
      "diff_10: 0.0010492508181889793\n",
      "QS_10: 0.0010369561715776634\n",
      "diff_21: 0.0006697980448278299\n",
      "MACDs_10_50_9: 0.0005590841874467804\n",
      "KST_10_15_20_30_10_10_10_15: 4.6321566691699364e-05\n",
      "CDL_RISEFALL3METHODS: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jnorm\\Projects\\websocket_trading\\.venv\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [ 46  50  52  55  57  58  77  80  81  82  87  90 101 104 105] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\jnorm\\Projects\\websocket_trading\\.venv\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 3 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n3 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\jnorm\\Projects\\websocket_trading\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\jnorm\\Projects\\websocket_trading\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1204, in fit\n    check_classification_targets(y)\n  File \"c:\\Users\\jnorm\\Projects\\websocket_trading\\.venv\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 218, in check_classification_targets\n    raise ValueError(\"Unknown label type: %r\" % y_type)\nValueError: Unknown label type: 'continuous'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[426], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m log_reg \u001b[39m=\u001b[39m LogisticRegression(random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m, max_iter\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[39m# Cross-validation\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m cv_scores \u001b[39m=\u001b[39m cross_val_score(log_reg, features_df_new, y, cv\u001b[39m=\u001b[39;49mtscv, scoring\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mf1\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     31\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mLogistic Regression CV F1 score: \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mmean(cv_scores)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[39m# Random Forest\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jnorm\\Projects\\websocket_trading\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[0;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[0;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[0;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[0;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    527\u001b[0m )\n\u001b[0;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\jnorm\\Projects\\websocket_trading\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:285\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m    266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m cv\u001b[39m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[1;32m--> 285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39mif\u001b[39;00m callable(scoring):\n",
      "File \u001b[1;32mc:\\Users\\jnorm\\Projects\\websocket_trading\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 3 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n3 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\jnorm\\Projects\\websocket_trading\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\jnorm\\Projects\\websocket_trading\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1204, in fit\n    check_classification_targets(y)\n  File \"c:\\Users\\jnorm\\Projects\\websocket_trading\\.venv\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 218, in check_classification_targets\n    raise ValueError(\"Unknown label type: %r\" % y_type)\nValueError: Unknown label type: 'continuous'\n"
     ]
    }
   ],
   "source": [
    "# Re-scale the data to include the new feature\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# feature selection\n",
    "selector = SelectKBest(score_func=f_classif, k=\"all\")\n",
    "selector.fit(X_scaled, y)\n",
    "\n",
    "# Get columns to keep and create new dataframe with those only\n",
    "cols = selector.get_support(indices=True)\n",
    "features_df_new = X.iloc[:, cols]\n",
    "\n",
    "# Store the scores of each feature in a dictionary\n",
    "feature_scores = {\n",
    "    feature_name: score for feature_name, score in zip(X.columns, selector.scores_)\n",
    "}\n",
    "\n",
    "# Sort the dictionary by value in descending order and print the scores\n",
    "for feature_name, score in sorted(\n",
    "    feature_scores.items(), key=lambda item: item[1], reverse=True\n",
    "):\n",
    "    print(f\"{feature_name}: {score}\")\n",
    "\n",
    "# Now we can apply Logistic Regression and Random Forests on the new features_df_new\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=500)\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(log_reg, features_df_new, y, cv=tscv, scoring=\"f1\")\n",
    "\n",
    "print(f\"\\nLogistic Regression CV F1 score: {np.mean(cv_scores)}\")\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(rf, features_df_new, y, cv=tscv, scoring=\"f1\")\n",
    "\n",
    "print(f\"Random Forest CV F1 score: {np.mean(cv_scores)}\")\n",
    "\n",
    "# Reshape input to be 3D [samples, timesteps, features]\n",
    "X_array = X.values\n",
    "X_reshaped = X_array.reshape((X_array.shape[0], 1, X_array.shape[1]))\n",
    "\n",
    "# Call the function\n",
    "mean_f1_score = timeseries_cv_score(X_reshaped, y.values, n_splits=5)\n",
    "print(f\"\\nLSTM CV F1 score: {mean_f1_score}\")\n",
    "\n",
    "print(\"\\n\", features_df_new.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression CV ROC AUC score: 0.5516985893932947\n",
      "Random Forest CV ROC AUC score: 0.9951631481367236\n",
      "\n",
      " Index(['open', 'close', 'high', 'low', 'volume', 'color', 'time',\n",
      "       'ABER_ZG_5_15', 'ABER_SG_5_15', 'ABER_XG_5_15',\n",
      "       ...\n",
      "       'price_ema5', 'volume_ema5', 'price_to_ema5', 'volume_change_roll5',\n",
      "       'avg_vol_last_100', 'turnover', 'hour', 'minute', 'day', 'month'],\n",
      "      dtype='object', length=484)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=500)\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(log_reg, X, y, cv=tscv, scoring=\"roc_auc\")\n",
    "\n",
    "print(f\"Logistic Regression CV ROC AUC score: {np.mean(cv_scores)}\")\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(rf, X, y, cv=tscv, scoring=\"roc_auc\")\n",
    "\n",
    "print(f\"Random Forest CV ROC AUC score: {np.mean(cv_scores)}\")\n",
    "\n",
    "print(\"\\n\", X.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 812us/step\n",
      "42/42 [==============================] - 0s 842us/step\n",
      "42/42 [==============================] - 0s 781us/step\n",
      "42/42 [==============================] - 0s 842us/step\n",
      "42/42 [==============================] - 0s 720us/step\n",
      "\n",
      "LSTM CV ROC AUC score: (0.6953945419128389, 0.4942367515727568)\n"
     ]
    }
   ],
   "source": [
    "# Reshape input to be 3D [samples, timesteps, features]\n",
    "X_array = X.values\n",
    "X_reshaped = X_array.reshape((X_array.shape[0], 1, X_array.shape[1]))\n",
    "\n",
    "# Call the function\n",
    "mean_auc_score = timeseries_cv_score(X_reshaped, y.values, n_splits=5)\n",
    "print(f\"\\nLSTM CV ROC AUC score: {mean_auc_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
