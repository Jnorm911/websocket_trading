{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports** 👌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.signal import detrend\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions** 🤌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(X, y, time_steps=60):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X.iloc[i:(i + time_steps)].values)\n",
    "        ys.append(y.iloc[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing & Feature Engineering** 👻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X:  (1923, 60, 51)\n",
      "Shape of y:  (1923,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "      <th>turnover</th>\n",
       "      <th>avg_vol_last_100</th>\n",
       "      <th>MACD_12_26_9</th>\n",
       "      <th>MACDh_12_26_9</th>\n",
       "      <th>MACDs_12_26_9</th>\n",
       "      <th>...</th>\n",
       "      <th>lag_8</th>\n",
       "      <th>lag_9</th>\n",
       "      <th>lag_10</th>\n",
       "      <th>volume_change</th>\n",
       "      <th>price_change</th>\n",
       "      <th>volatility</th>\n",
       "      <th>trend</th>\n",
       "      <th>seasonal</th>\n",
       "      <th>rolling_var</th>\n",
       "      <th>detrended_close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-03 14:00:00</th>\n",
       "      <td>0.006596</td>\n",
       "      <td>0.006319</td>\n",
       "      <td>0.009867</td>\n",
       "      <td>0.003050</td>\n",
       "      <td>0.163359</td>\n",
       "      <td>0.112966</td>\n",
       "      <td>0.124722</td>\n",
       "      <td>0.387319</td>\n",
       "      <td>0.514991</td>\n",
       "      <td>0.390588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009328</td>\n",
       "      <td>0.006722</td>\n",
       "      <td>0.005338</td>\n",
       "      <td>0.043062</td>\n",
       "      <td>0.464726</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.759607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.361351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03 15:00:00</th>\n",
       "      <td>0.005775</td>\n",
       "      <td>0.003007</td>\n",
       "      <td>0.005017</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>0.097420</td>\n",
       "      <td>0.067041</td>\n",
       "      <td>0.133524</td>\n",
       "      <td>0.383776</td>\n",
       "      <td>0.505716</td>\n",
       "      <td>0.389828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008244</td>\n",
       "      <td>0.009328</td>\n",
       "      <td>0.006722</td>\n",
       "      <td>0.023002</td>\n",
       "      <td>0.431732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.993017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.355817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03 16:00:00</th>\n",
       "      <td>0.003696</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.003120</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>0.104484</td>\n",
       "      <td>0.071915</td>\n",
       "      <td>0.143028</td>\n",
       "      <td>0.380366</td>\n",
       "      <td>0.498641</td>\n",
       "      <td>0.388473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007940</td>\n",
       "      <td>0.008244</td>\n",
       "      <td>0.009328</td>\n",
       "      <td>0.046555</td>\n",
       "      <td>0.456176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.801137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.354038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03 17:00:00</th>\n",
       "      <td>0.002225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028038</td>\n",
       "      <td>0.019186</td>\n",
       "      <td>0.139485</td>\n",
       "      <td>0.376111</td>\n",
       "      <td>0.490782</td>\n",
       "      <td>0.386458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008873</td>\n",
       "      <td>0.007940</td>\n",
       "      <td>0.008244</td>\n",
       "      <td>0.007632</td>\n",
       "      <td>0.443234</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.350279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03 18:00:00</th>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001926</td>\n",
       "      <td>0.023794</td>\n",
       "      <td>0.016285</td>\n",
       "      <td>0.135450</td>\n",
       "      <td>0.373692</td>\n",
       "      <td>0.489276</td>\n",
       "      <td>0.384316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009092</td>\n",
       "      <td>0.008873</td>\n",
       "      <td>0.007940</td>\n",
       "      <td>0.036920</td>\n",
       "      <td>0.475342</td>\n",
       "      <td>0.073654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.908196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.351431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         open     close      high       low    volume  \\\n",
       "time                                                                    \n",
       "2023-01-03 14:00:00  0.006596  0.006319  0.009867  0.003050  0.163359   \n",
       "2023-01-03 15:00:00  0.005775  0.003007  0.005017  0.001242  0.097420   \n",
       "2023-01-03 16:00:00  0.003696  0.002151  0.003120  0.000803  0.104484   \n",
       "2023-01-03 17:00:00  0.002225  0.000000  0.001562  0.000000  0.028038   \n",
       "2023-01-03 18:00:00  0.000407  0.001061  0.000000  0.001926  0.023794   \n",
       "\n",
       "                     turnover  avg_vol_last_100  MACD_12_26_9  MACDh_12_26_9  \\\n",
       "time                                                                           \n",
       "2023-01-03 14:00:00  0.112966          0.124722      0.387319       0.514991   \n",
       "2023-01-03 15:00:00  0.067041          0.133524      0.383776       0.505716   \n",
       "2023-01-03 16:00:00  0.071915          0.143028      0.380366       0.498641   \n",
       "2023-01-03 17:00:00  0.019186          0.139485      0.376111       0.490782   \n",
       "2023-01-03 18:00:00  0.016285          0.135450      0.373692       0.489276   \n",
       "\n",
       "                     MACDs_12_26_9  ...     lag_8     lag_9    lag_10  \\\n",
       "time                                ...                                 \n",
       "2023-01-03 14:00:00       0.390588  ...  0.009328  0.006722  0.005338   \n",
       "2023-01-03 15:00:00       0.389828  ...  0.008244  0.009328  0.006722   \n",
       "2023-01-03 16:00:00       0.388473  ...  0.007940  0.008244  0.009328   \n",
       "2023-01-03 17:00:00       0.386458  ...  0.008873  0.007940  0.008244   \n",
       "2023-01-03 18:00:00       0.384316  ...  0.009092  0.008873  0.007940   \n",
       "\n",
       "                     volume_change  price_change  volatility  trend  seasonal  \\\n",
       "time                                                                            \n",
       "2023-01-03 14:00:00       0.043062      0.464726    0.000000    NaN  0.759607   \n",
       "2023-01-03 15:00:00       0.023002      0.431732    0.000000    NaN  0.993017   \n",
       "2023-01-03 16:00:00       0.046555      0.456176    0.000000    NaN  0.801137   \n",
       "2023-01-03 17:00:00       0.007632      0.443234    0.000000    NaN  0.762805   \n",
       "2023-01-03 18:00:00       0.036920      0.475342    0.073654    NaN  0.908196   \n",
       "\n",
       "                     rolling_var  detrended_close  \n",
       "time                                               \n",
       "2023-01-03 14:00:00          0.0         0.361351  \n",
       "2023-01-03 15:00:00          0.0         0.355817  \n",
       "2023-01-03 16:00:00          0.0         0.354038  \n",
       "2023-01-03 17:00:00          0.0         0.350279  \n",
       "2023-01-03 18:00:00          0.0         0.351431  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data_path = \"kc_btc_60min_ha_ti.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Convert 'time' column to datetime format and set as index\n",
    "df['time'] = pd.to_datetime(df['time'], unit='s')  # Assuming 'time' is in Unix timestamp format\n",
    "df.set_index('time', inplace=True)\n",
    "\n",
    "# Handle missing values and duplicates\n",
    "df.fillna(method='ffill', inplace=True)  # Forward fill\n",
    "df.fillna(method='bfill', inplace=True)  # Backward fill\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Replace infinite values\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Convert categorical variables to numerical\n",
    "df[\"color_num\"] = df[\"color\"].map({'green': 1, 'red': 0}) \n",
    "\n",
    "# Create new column for color change\n",
    "df['color_change'] = df['color_num'].diff().abs()\n",
    "df['color_change'].fillna(0, inplace=True)\n",
    "\n",
    "# Drop the original 'color' column\n",
    "df = df.drop('color', axis=1)\n",
    "\n",
    "# Create lag features\n",
    "window_size = 10  # Increasing the number of lags\n",
    "for i in range(window_size):\n",
    "    df[f\"lag_{i+1}\"] = df[\"close\"].shift(i + 1)\n",
    "\n",
    "# Drop rows with missing values (created by lag features)\n",
    "df = df.dropna()\n",
    "\n",
    "# Include more features\n",
    "feature_cols = ['open', 'high', 'low', 'close', 'volume', 'turnover', 'avg_vol_last_100', 'MACD_12_26_9', 'MACDh_12_26_9', 'MACDs_12_26_9', 'PP', 'R1', 'S1', 'R2', 'S2', 'R3', 'S3', 'BBL_5_2.0', 'BBM_5_2.0', 'BBU_5_2.0', 'BBB_5_2.0', 'BBP_5_2.0', 'RSI', 'SMA_5', 'SMA_10', 'SMA_20', 'EMA_5', 'EMA_10', 'EMA_20', 'STOCHk_14_3_3', 'STOCHd_14_3_3', 'ATR', 'ROC', 'CCI'] + [f\"lag_{i+1}\" for i in range(window_size)]\n",
    "\n",
    "# Volume Change\n",
    "df['volume_change'] = df['volume'].pct_change()\n",
    "df['volume_change'].fillna(0, inplace=True)\n",
    "\n",
    "# Price Change (Close Price)\n",
    "df['price_change'] = df['close'].pct_change()\n",
    "df['price_change'].fillna(0, inplace=True)\n",
    "\n",
    "# Volatility (e.g., standard deviation of price changes over past N periods)\n",
    "N = 5  # Choose a value for N\n",
    "df['volatility'] = df['price_change'].rolling(window=N).std()\n",
    "df['volatility'].fillna(0, inplace=True)\n",
    "\n",
    "# Extract trend and seasonal components\n",
    "result = seasonal_decompose(df['close'], model='additive', period=24)  # for hourly data, 24 could be a starting point for period\n",
    "df['trend'] = result.trend\n",
    "df['seasonal'] = result.seasonal\n",
    "\n",
    "# Calculate rolling variance\n",
    "df['rolling_var'] = df['close'].rolling(window=24).var()\n",
    "df['rolling_var'].fillna(0, inplace=True)\n",
    "\n",
    "# Detrend the 'close' column\n",
    "df['detrended_close'] = detrend(df['close'])\n",
    "\n",
    "# Update feature_cols list\n",
    "feature_cols += ['volume_change', 'price_change', 'volatility', 'trend', 'seasonal', 'rolling_var', 'detrended_close']\n",
    "\n",
    "# Normalize, but exclude 'RSI' and 'color_num'\n",
    "to_normalize = [col for col in feature_cols if col not in ['RSI', 'color_num']]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df[to_normalize] = scaler.fit_transform(df[to_normalize])\n",
    "\n",
    "# Create sequences\n",
    "features = df[feature_cols]\n",
    "target = df['color_change']\n",
    "X, y = create_sequences(features, target, time_steps)\n",
    "\n",
    "# Check the shape of the data\n",
    "print(\"Shape of X: \", X.shape)\n",
    "print(\"Shape of y: \", y.shape)\n",
    "\n",
    "# Checking the first few rows\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train-Test**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model** 🏴‍☠️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1388 595\n",
      "Shape of X_train:  (1328, 60, 51)\n",
      "Shape of y_train:  (1328,)\n",
      "Shape of X_test:  (535, 60, 51)\n",
      "Shape of y_test:  (535,)\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 1s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 0s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 0s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 0s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 0s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 1s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 1s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 0s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 0s 11ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 1s 12ms/step - loss: nan - val_loss: nan\n",
      "17/17 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m     34\u001b[0m \u001b[39m# Since this is a regression problem, you might want to use Mean Squared Error (MSE) as the evaluation metric\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mModel MSE: \u001b[39m\u001b[39m\"\u001b[39m, mean_squared_error(y_test, y_pred))\n",
      "File \u001b[1;32mc:\\Users\\jnorm\\Projects\\websocket_trading\\.venv\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmean_squared_error\u001b[39m(\n\u001b[0;32m    383\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, multioutput\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39muniform_average\u001b[39m\u001b[39m\"\u001b[39m, squared\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    384\u001b[0m ):\n\u001b[0;32m    385\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Mean squared error regression loss.\u001b[39;00m\n\u001b[0;32m    386\u001b[0m \n\u001b[0;32m    387\u001b[0m \u001b[39m    Read more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[39m    0.825...\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 442\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[39m=\u001b[39m _check_reg_targets(\n\u001b[0;32m    443\u001b[0m         y_true, y_pred, multioutput\n\u001b[0;32m    444\u001b[0m     )\n\u001b[0;32m    445\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    446\u001b[0m     output_errors \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39maverage((y_true \u001b[39m-\u001b[39m y_pred) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, weights\u001b[39m=\u001b[39msample_weight)\n",
      "File \u001b[1;32mc:\\Users\\jnorm\\Projects\\websocket_trading\\.venv\\lib\\site-packages\\sklearn\\metrics\\_regression.py:102\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m    101\u001b[0m y_true \u001b[39m=\u001b[39m check_array(y_true, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m--> 102\u001b[0m y_pred \u001b[39m=\u001b[39m check_array(y_pred, ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    104\u001b[0m \u001b[39mif\u001b[39;00m y_true\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    105\u001b[0m     y_true \u001b[39m=\u001b[39m y_true\u001b[39m.\u001b[39mreshape((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\jnorm\\Projects\\websocket_trading\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    916\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    918\u001b[0m         )\n\u001b[0;32m    920\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 921\u001b[0m         _assert_all_finite(\n\u001b[0;32m    922\u001b[0m             array,\n\u001b[0;32m    923\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    924\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    925\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    926\u001b[0m         )\n\u001b[0;32m    928\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mc:\\Users\\jnorm\\Projects\\websocket_trading\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    145\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    148\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m     )\n\u001b[1;32m--> 161\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Train-test split\n",
    "train_size = int(len(df) * 0.7)  # 70% of data for training\n",
    "test_size = len(df) - train_size\n",
    "\n",
    "train, test = df.iloc[0:train_size], df.iloc[train_size:len(df)]\n",
    "print(len(train), len(test))\n",
    "\n",
    "# Create train and test sets for features and target\n",
    "X_train, y_train = create_sequences(train[feature_cols], train['color_change'], time_steps)\n",
    "X_test, y_test = create_sequences(test[feature_cols], test['color_change'], time_steps)\n",
    "\n",
    "# Check the shape of the data\n",
    "print(\"Shape of X_train: \", X_train.shape)\n",
    "print(\"Shape of y_train: \", y_train.shape)\n",
    "print(\"Shape of X_test: \", X_test.shape)\n",
    "print(\"Shape of y_test: \", y_test.shape)\n",
    "\n",
    "# Define LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Since this is a regression problem, you might want to use Mean Squared Error (MSE) as the evaluation metric\n",
    "print(\"Model MSE: \", mean_squared_error(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
