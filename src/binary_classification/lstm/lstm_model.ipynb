{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports** ðŸ•µï¸â€â™‚ï¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from scipy.signal import detrend\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions** ðŸ¤Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(X, y, time_steps=60):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X.iloc[i:(i + time_steps)].values)\n",
    "        ys.append(y.iloc[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Globals** ðŸŒŽ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set display options to show all rows and columns\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing** ðŸ‘»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data: (1577, 1, 85)\n",
      "Shape of test data: (395, 1, 85)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('../../../data/kc/btc/heiken_ashi/with_trade_indicators/raw/kc_btc_60min_ha_ti.csv')\n",
    "\n",
    "# Convert color to 0 for 'red' and 1 for 'green'\n",
    "df['color'] = df['color'].map({'red': 0, 'green': 1})\n",
    "\n",
    "# Add 'color_change' column: 1 if color changes from the previous row, 0 otherwise\n",
    "df['color_change'] = df['color'].diff().abs()\n",
    "\n",
    "# Fill the first row's 'color_change' with 0\n",
    "df['color_change'].fillna(0, inplace=True)\n",
    "\n",
    "# Drop 'time', 'color', and 'turnover' columns\n",
    "df = df.drop(['time', 'color', 'turnover'], axis=1)\n",
    "\n",
    "# Separate features and target\n",
    "features = df.drop('color_change', axis=1)\n",
    "target = df['color_change']\n",
    "\n",
    "# Fill NaNs in specific columns with 0\n",
    "features['PSARl_0.01_0.1'] = features['PSARl_0.01_0.1'].fillna(0)\n",
    "features['PSARs_0.01_0.1'] = features['PSARs_0.01_0.1'].fillna(0)\n",
    "\n",
    "# Identify the first non-null row\n",
    "first_valid_index = features.dropna().index[0]\n",
    "\n",
    "# Drop the rows before this index\n",
    "features = features.loc[first_valid_index:]\n",
    "target = target.loc[first_valid_index:]\n",
    "\n",
    "# Use ffill to fill any remaining missing values\n",
    "features.ffill(inplace=True)\n",
    "\n",
    "cols_to_scale = [\n",
    "    'open', 'close', 'high', 'low', 'volume', 'avg_vol_last_100', 'obv',\n",
    "    'RSI_5', 'RSI_10', 'RSI_14', 'ROC_14', 'ROC_10', 'ROC_5', 'ATR_14', 'ATR_10', 'ATR_5',\n",
    "    'PP', 'R1', 'S1', 'R2', 'S2', 'R3', 'S3'\n",
    "]\n",
    "\n",
    "# Scale the selected columns\n",
    "scaler = MinMaxScaler()\n",
    "features[cols_to_scale] = scaler.fit_transform(features[cols_to_scale])\n",
    "\n",
    "# Determine the split point\n",
    "split_point = int(len(features) * 0.8)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test = features[:split_point], features[split_point:]\n",
    "y_train, y_test = target[:split_point], target[split_point:]\n",
    "\n",
    "# Reset indices\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "# Reshape input to be 3D [samples, timesteps, features] for LSTM\n",
    "X_train = X_train.values.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_test = X_test.values.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "\n",
    "print('Shape of train data:', X_train.shape)\n",
    "print('Shape of test data:', X_test.shape)\n",
    "\n",
    "# print(features.head(1))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross Validation** ðŸ´â€â˜ ï¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 688us/step\n",
      "Accuracy: 0.5114503816793893\n",
      "9/9 [==============================] - 0s 625us/step\n",
      "Accuracy: 0.46564885496183206\n",
      "9/9 [==============================] - 0s 626us/step\n",
      "Accuracy: 0.5114503816793893\n",
      "9/9 [==============================] - 0s 626us/step\n",
      "Accuracy: 0.48854961832061067\n",
      "9/9 [==============================] - 0s 688us/step\n",
      "Accuracy: 0.42748091603053434\n"
     ]
    }
   ],
   "source": [
    "# Initialize TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Define model architecture outside the loop\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Loop through the splits\n",
    "for train_index, test_index in tscv.split(X_train):\n",
    "    X_train_cv, X_test_cv = X_train[train_index], X_train[test_index]\n",
    "    y_train_cv, y_test_cv = y_train[train_index], y_train[test_index]\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X_train_cv, y_train_cv, epochs=50, verbose=0)\n",
    "\n",
    "    y_pred = model.predict(X_test_cv)\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    # Calculate accuracy (or any other metric you are interested in)\n",
    "    accuracy = accuracy_score(y_test_cv, y_pred)\n",
    "\n",
    "    print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
