{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    df = pd.read_csv(data_path)\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess_data(df):\n",
    "    # Convert 'color' column to binary representation\n",
    "    df[\"color\"] = df[\"color\"].map({\"red\": 0, \"green\": 1})\n",
    "\n",
    "    df[\"color_change\"] = df[\"color\"].diff().ne(0).astype(int)\n",
    "    df[\"color_change\"].fillna(0, inplace=True)\n",
    "\n",
    "    # Fill NaNs in specified columns with 0\n",
    "    df[\"PSARl_0.01_0.1\"].fillna(0, inplace=True)\n",
    "    df[\"PSARs_0.01_0.1\"].fillna(0, inplace=True)\n",
    "    df[\"ICS_15\"].fillna(0, inplace=True)\n",
    "\n",
    "    # Forward Fill\n",
    "    df.ffill(inplace=True)\n",
    "\n",
    "    # Backward Fill\n",
    "    df.bfill(inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def scale_data(df):\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "    return df_scaled\n",
    "\n",
    "\n",
    "def create_features(df):\n",
    "    df[\"BBP_diff\"] = df[\"BBP_10_2.0_10\"] - df[\"BBP_5_2.0_5\"]\n",
    "    df[\"CCI_diff\"] = df[\"CCI_10\"] - df[\"CCI_5\"]\n",
    "    df[\"RVI_diff\"] = df[\"RVI_10\"] - df[\"RVI_5\"]\n",
    "    df[\"RSI_diff\"] = df[\"RSI_14\"] - df[\"RSI_5\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_for_lstm(df, target_column, time_steps):\n",
    "    # Check if target_column is in df\n",
    "    if target_column not in df.columns:\n",
    "        print(f\"Target column '{target_column}' not found in DataFrame.\")\n",
    "        return None, None\n",
    "\n",
    "    # Drop the target column from X\n",
    "    X = df.drop(target_column, axis=1).values\n",
    "\n",
    "    # Create y from the target column\n",
    "    y = df[target_column].values\n",
    "\n",
    "    # Reshape X to (samples, time_steps, features)\n",
    "    X = np.array([X[i - time_steps : i] for i in range(time_steps, len(X))])\n",
    "\n",
    "    # Reshape y to (samples, )\n",
    "    y = y[time_steps:]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def feature_importance(X, y):\n",
    "    # Use RandomForestClassifier to evaluate feature importance\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    importances = model.feature_importances_\n",
    "    return importances\n",
    "\n",
    "\n",
    "# Define the model\n",
    "def create_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation=\"relu\", input_shape=input_shape))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Globals ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set display options to show all rows and columns\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Load the data\n",
    "data_path = (\n",
    "    \"../../../data/kc/btc/heiken_ashi/with_trade_indicators/raw/kc_btc_12min_ha_ti.csv\"\n",
    ")\n",
    "\n",
    "# List of features to drop\n",
    "features_to_drop = [\n",
    "    ## Set 3\n",
    "    \"ROC_5\",\n",
    "    \"EMA_5\",\n",
    "    \"PP\",\n",
    "    \"RSI_5\",\n",
    "    \"MACDh_12_26_9\",\n",
    "    \"BBL_15_2.0_15\",\n",
    "    \"BBM_15_2.0_15\",\n",
    "    \"MACDs_6_13_5_6_13_5\",\n",
    "    \"BBB_20_2.0_20\",\n",
    "    \"STOCHd_14_3_3\",\n",
    "    \"TRIX_12_6\",\n",
    "    \"STOCHk_14_3_3_10_3_3\",\n",
    "    \"avg_vol_last_100\",\n",
    "    ## Set 2\n",
    "    \"BBP_5_2.0_5\",\n",
    "    \"RVI_15\",\n",
    "    \"close\",\n",
    "    \"obv\",\n",
    "    \"BBU_15_2.0_15\",\n",
    "    \"SMA_10\",\n",
    "    \"turnover\",\n",
    "    \"BBM_10_2.0_10\",\n",
    "    \"ICS_15\",\n",
    "    \"TRIXs_10_5\",\n",
    "    \"STOCHd_14_3_3_7_3_3\",\n",
    "    \"PSARs_0.01_0.1\",\n",
    "    ## Set 1\n",
    "    \"BBU_20_2.0_20\",\n",
    "    \"ROC_10\",\n",
    "    \"low\",\n",
    "    \"volume\",\n",
    "    \"STOCHk_14_3_3_10_3_3\",\n",
    "    \"MACDs_12_26_9\",\n",
    "    \"CCI_5\",\n",
    "    \"BBM_20_2.0_20\",\n",
    "    \"SMA_5\",\n",
    "    \"RSI_14\",\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(data_path)\n",
    "\n",
    "# Preprocess the data\n",
    "df = preprocess_data(df)\n",
    "\n",
    "# Create features (if you have the function)\n",
    "df = create_features(df)\n",
    "\n",
    "# Scale the data\n",
    "df_scaled = scale_data(df)\n",
    "\n",
    "# Prepare data for LSTM\n",
    "time_steps = 60  # choose based on your needs\n",
    "X_lstm, y_lstm = prepare_for_lstm(df_scaled, \"color_change\", time_steps)\n",
    "\n",
    "# Prepare TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model cross-validated accuracy: 0.5793650793650793\n"
     ]
    }
   ],
   "source": [
    "# Drop the unnecessary columns before scaling\n",
    "X = df.drop(\"color_change\", axis=1)\n",
    "X = X.drop(columns=features_to_drop)\n",
    "\n",
    "# Scale the data\n",
    "X_scaled = scale_data(X)\n",
    "X_scaled = X_scaled.values  # Convert DataFrame to numpy array\n",
    "\n",
    "# Perform cross-validation\n",
    "accuracies = []\n",
    "\n",
    "for train_index, test_index in tscv.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Define and train the model\n",
    "    base_model = LogisticRegression(max_iter=500)\n",
    "    base_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = base_model.predict(X_test)\n",
    "\n",
    "    # Compute accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Print the mean accuracy over all folds\n",
    "print(f\"Base model cross-validated accuracy: {np.mean(accuracies)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare your data for Random Forest\n",
    "# For example, use the first 60 days as features and the color change of the 61st day as the target.\n",
    "X_rf = df_scaled.iloc[:-1]  # All but the last row\n",
    "y_rf = df[\"color_change\"].iloc[1:]  # All but the first row\n",
    "\n",
    "importances = feature_importance(X_rf, y_rf)\n",
    "\n",
    "# Output the feature importance in descending order\n",
    "features = df.columns\n",
    "importance_df = pd.DataFrame({\"Feature\": features, \"Importance\": importances})\n",
    "importance_df = importance_df.sort_values(\"Importance\", ascending=False)\n",
    "print(importance_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Feature 1             Feature 2  Correlation\n",
      "3289        PSARs_0.01_0.1        PSARl_0.01_0.1    -0.968489\n",
      "3197        PSARl_0.01_0.1        PSARs_0.01_0.1    -0.968489\n",
      "6044         BBP_10_2.0_10              RSI_diff    -0.851724\n",
      "8620              RSI_diff         BBP_10_2.0_10    -0.851724\n",
      "8582              RSI_diff                CCI_10    -0.836207\n",
      "2510                CCI_10              RSI_diff    -0.836207\n",
      "8583              RSI_diff                 CCI_5    -0.815109\n",
      "2603                 CCI_5              RSI_diff    -0.815109\n",
      "5579           BBP_5_2.0_5              RSI_diff    -0.811188\n",
      "8615              RSI_diff           BBP_5_2.0_5    -0.811188\n",
      "1580                 RSI_5              RSI_diff    -0.795455\n",
      "8572              RSI_diff                 RSI_5    -0.795455\n",
      "8496              RVI_diff                 RVI_5    -0.771021\n",
      "3160                 RVI_5              RVI_diff    -0.771021\n",
      "3161                 RVI_5              RSI_diff    -0.760581\n",
      "8589              RSI_diff                 RVI_5    -0.760581\n",
      "8581              RSI_diff                CCI_14    -0.756051\n",
      "2417                CCI_14              RSI_diff    -0.756051\n",
      "8625              RSI_diff         BBP_15_2.0_15    -0.751238\n",
      "6509         BBP_15_2.0_15              RSI_diff    -0.751238\n",
      "3068                RVI_10              RSI_diff    -0.662197\n",
      "8588              RSI_diff                RVI_10    -0.662197\n",
      "8630              RSI_diff         BBP_20_2.0_20    -0.633720\n",
      "6974         BBP_20_2.0_20              RSI_diff    -0.633720\n",
      "8522              RVI_diff           BBP_5_2.0_5    -0.627899\n",
      "5578           BBP_5_2.0_5              RVI_diff    -0.627899\n",
      "6043         BBP_10_2.0_10              RVI_diff    -0.620800\n",
      "8527              RVI_diff         BBP_10_2.0_10    -0.620800\n",
      "8636              RSI_diff   MACDh_6_13_5_6_13_5    -0.617698\n",
      "7532   MACDh_6_13_5_6_13_5              RSI_diff    -0.617698\n",
      "2602                 CCI_5              RVI_diff    -0.617292\n",
      "8490              RVI_diff                 CCI_5    -0.617292\n",
      "2509                CCI_10              RVI_diff    -0.612309\n",
      "8489              RVI_diff                CCI_10    -0.612309\n",
      "8638              RSI_diff         STOCHk_14_3_3    -0.567046\n",
      "8642              RSI_diff  STOCHk_14_3_3_10_3_3    -0.567046\n",
      "8090  STOCHk_14_3_3_10_3_3              RSI_diff    -0.567046\n",
      "7904   STOCHk_14_3_3_7_3_3              RSI_diff    -0.567046\n",
      "7718         STOCHk_14_3_3              RSI_diff    -0.567046\n",
      "8640              RSI_diff   STOCHk_14_3_3_7_3_3    -0.567046\n",
      "8587              RSI_diff                RVI_15    -0.564979\n",
      "2975                RVI_15              RSI_diff    -0.564979\n",
      "3272        PSARs_0.01_0.1                RSI_10    -0.549750\n",
      "1616                RSI_10        PSARs_0.01_0.1    -0.549750\n",
      "6917         BBP_20_2.0_20        PSARs_0.01_0.1    -0.547919\n",
      "3329        PSARs_0.01_0.1         BBP_20_2.0_20    -0.547919\n",
      "8479              RVI_diff                 RSI_5    -0.542566\n",
      "1579                 RSI_5              RVI_diff    -0.542566\n",
      "3273        PSARs_0.01_0.1                RSI_14    -0.533495\n",
      "1709                RSI_14        PSARs_0.01_0.1    -0.533495\n",
      "3285        PSARs_0.01_0.1                   mfi    -0.532883\n",
      "2825                   mfi        PSARs_0.01_0.1    -0.532883\n",
      "8488              RVI_diff                CCI_14    -0.514694\n",
      "2416                CCI_14              RVI_diff    -0.514694\n",
      "2324                 ROC_5              RSI_diff    -0.502161\n",
      "8580              RSI_diff                 ROC_5    -0.502161\n"
     ]
    }
   ],
   "source": [
    "# Compute pairwise correlation of columns\n",
    "corr = df.corr()\n",
    "\n",
    "# Set a lower threshold for correlations you want to display\n",
    "threshold = -0.6\n",
    "\n",
    "# Extract feature pairs with correlations below the threshold\n",
    "filtered_correlations = corr.stack().reset_index()\n",
    "filtered_correlations.columns = [\"Feature 1\", \"Feature 2\", \"Correlation\"]\n",
    "filtered_correlations = filtered_correlations[\n",
    "    (filtered_correlations[\"Feature 1\"] != filtered_correlations[\"Feature 2\"])\n",
    "    & (filtered_correlations[\"Correlation\"] <= threshold)\n",
    "]\n",
    "\n",
    "# Sort the filtered correlations by value and remove duplicates\n",
    "filtered_correlations = filtered_correlations.sort_values(\n",
    "    by=\"Correlation\", ascending=True\n",
    ").drop_duplicates()\n",
    "print(filtered_correlations)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a dataframe to hold results\n",
    "# results = pd.DataFrame(columns=[\"feature\", \"accuracy\"])\n",
    "\n",
    "# # Feature ablation\n",
    "# for column in X.columns:\n",
    "#     print(f\"Running model without {column}\")\n",
    "#     X_temp = X.drop(column, axis=1)\n",
    "#     X_temp = X_temp.values.reshape((X_temp.shape[0], X_temp.shape[1], 1))\n",
    "#     accuracies = []  # list to hold accuracies for each split\n",
    "\n",
    "#     # Perform TimeSeriesSplit\n",
    "#     for train_index, test_index in tscv.split(X_temp):\n",
    "#         X_train, X_test = X_temp[train_index], X_temp[test_index]\n",
    "#         y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "#         # Create and fit the model\n",
    "#         model = create_model((X_train.shape[1], 1))\n",
    "#         model.fit(X_train, y_train, epochs=10, verbose=0)\n",
    "\n",
    "#         # Make predictions on the test set\n",
    "#         y_pred = model.predict(X_test)\n",
    "#         y_pred = (y_pred > 0.5).astype(int).flatten()\n",
    "#         accuracy = accuracy_score(y_test, y_pred)\n",
    "#         accuracies.append(accuracy)\n",
    "\n",
    "#     # Calculate average accuracy for this feature\n",
    "#     avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "#     print(f\"Average accuracy without {column}: {avg_accuracy}\")\n",
    "#     results = results.append(\n",
    "#         {\"feature\": column, \"accuracy\": avg_accuracy}, ignore_index=True\n",
    "#     )\n",
    "\n",
    "#     # Save results to CSV\n",
    "#     results.to_csv(f\"ablation_{column}.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 feature   accuracy\n",
      "64                RVI_10  76.371568\n",
      "8                    obv  76.309228\n",
      "84                ISB_15  76.309228\n",
      "76        PSARr_0.01_0.1  76.309228\n",
      "4               turnover  76.246881\n",
      "30         BBL_20_2.0_20  76.246881\n",
      "42         BBM_10_2.0_10  76.184541\n",
      "87                ICS_15  76.184541\n",
      "82            TRIXs_10_5  76.122195\n",
      "36           BBL_5_2.0_5  76.122195\n",
      "10                RSI_10  76.059848\n",
      "46         STOCHk_14_3_3  76.059848\n",
      "21                 EMA_2  76.059848\n",
      "34         BBP_20_2.0_20  76.059848\n",
      "80            TRIXs_12_6  75.997508\n",
      "60                 CCI_5  75.997508\n",
      "59                CCI_10  75.997508\n",
      "85                 ITS_5  75.997508\n",
      "78            TRIXs_18_9  75.935161\n",
      "72                    S3  75.935161\n",
      "53                ATR_10  75.935161\n",
      "49   STOCHd_14_3_3_7_3_3  75.935161\n",
      "48   STOCHk_14_3_3_7_3_3  75.935161\n",
      "54                 ATR_5  75.872821\n",
      "0                   open  75.872821\n",
      "14         MACDs_12_26_9  75.810474\n",
      "32         BBU_20_2.0_20  75.810474\n",
      "12          MACD_12_26_9  75.810474\n",
      "67                    R1  75.810474\n",
      "68                    S1  75.810474\n",
      "73        PSARl_0.01_0.1  75.810474\n",
      "6                 volume  75.810474\n",
      "51  STOCHd_14_3_3_10_3_3  75.810474\n",
      "27         BBU_15_2.0_15  75.810474\n",
      "24         BBP_10_2.0_10  75.810474\n",
      "2                    low  75.748128\n",
      "55                ROC_14  75.748128\n",
      "63                RVI_15  75.748128\n",
      "28         BBB_15_2.0_15  75.748128\n",
      "58                CCI_14  75.748128\n",
      "15    MACD_6_13_5_6_13_5  75.748128\n",
      "61                   cmf  75.748128\n",
      "41         BBL_10_2.0_10  75.748128\n",
      "57                 ROC_5  75.748128\n",
      "31         BBM_20_2.0_20  75.748128\n",
      "81             TRIX_10_5  75.685787\n",
      "43         BBU_10_2.0_10  75.685787\n",
      "70                    S2  75.685787\n",
      "52                ATR_14  75.685787\n",
      "37           BBM_5_2.0_5  75.685787\n",
      "22                 EMA_5  75.685787\n",
      "77             TRIX_18_9  75.685787\n",
      "44         BBB_10_2.0_10  75.623441\n",
      "66                    PP  75.623441\n",
      "1                   high  75.623441\n",
      "9                  RSI_5  75.623441\n",
      "29         BBP_15_2.0_15  75.623441\n",
      "20                SMA_10  75.623441\n",
      "71                    R3  75.561094\n",
      "13         MACDh_12_26_9  75.561094\n",
      "25         BBL_15_2.0_15  75.561094\n",
      "26         BBM_15_2.0_15  75.561094\n",
      "17   MACDs_6_13_5_6_13_5  75.561094\n",
      "33         BBB_20_2.0_20  75.561094\n",
      "35   bollinger_bandwidth  75.561094\n",
      "16   MACDh_6_13_5_6_13_5  75.498754\n",
      "19                 SMA_5  75.498754\n",
      "79             TRIX_12_6  75.498754\n",
      "75       PSARaf_0.01_0.1  75.436407\n",
      "86                IKS_15  75.436407\n",
      "65                 RVI_5  75.436407\n",
      "18                SMA_20  75.436407\n",
      "45         BBP_10_2.0_10  75.436407\n",
      "3                  close  75.374067\n",
      "74        PSARs_0.01_0.1  75.374067\n",
      "62                   mfi  75.374067\n",
      "50  STOCHk_14_3_3_10_3_3  75.374067\n",
      "56                ROC_10  75.374067\n",
      "69                    R2  75.311720\n",
      "39           BBB_5_2.0_5  75.249374\n",
      "38           BBU_5_2.0_5  75.249374\n",
      "23                EMA_10  75.249374\n",
      "83                 ISA_5  75.249374\n",
      "47         STOCHd_14_3_3  75.187033\n",
      "11                RSI_14  75.124687\n",
      "40           BBP_5_2.0_5  74.812967\n",
      "7       avg_vol_last_100  73.004985\n",
      "5                  color  54.488778\n"
     ]
    }
   ],
   "source": [
    "## Read ablation file ##\n",
    "\n",
    "# Load the DataFrame\n",
    "df = pd.read_csv(\"model_accuracy_results.csv\")\n",
    "\n",
    "# Sort the DataFrame by 'accuracy' from lowest to highest\n",
    "df_sorted = df.sort_values(by=\"accuracy\", ascending=False)\n",
    "\n",
    "# # Sample 50% of the DataFrame\n",
    "# df_sampled = df_sorted.sample(frac=0.5)\n",
    "\n",
    "# Display the sampled DataFrame\n",
    "print(df_sorted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
