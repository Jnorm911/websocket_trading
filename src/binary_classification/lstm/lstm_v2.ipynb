{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "import xgboost as xgb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set display options to show all rows and columns\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "features = [\n",
    "    # Fundamental price data\n",
    "    \"open\",\n",
    "    \"high\",\n",
    "    \"low\",\n",
    "    \"close\",\n",
    "    # Auxiliary data\n",
    "    \"turnover\",\n",
    "    \"color\",\n",
    "    # Volume-related\n",
    "    \"volume\",\n",
    "    \"avg_vol_last_100\",\n",
    "    \"obv\",\n",
    "    # Momentum and trend indicators\n",
    "    \"RSI_5\",\n",
    "    \"RSI_10\",\n",
    "    \"RSI_14\",\n",
    "    \"MACD_12_26_9\",\n",
    "    \"MACDh_12_26_9\",\n",
    "    \"MACDs_12_26_9\",\n",
    "    \"MACD_6_13_5_6_13_5\",\n",
    "    \"MACDh_6_13_5_6_13_5\",\n",
    "    \"MACDs_6_13_5_6_13_5\",\n",
    "    # Moving averages\n",
    "    \"SMA_20\",\n",
    "    \"SMA_5\",\n",
    "    \"SMA_10\",\n",
    "    \"EMA_2\",\n",
    "    \"EMA_5\",\n",
    "    \"EMA_10\",\n",
    "    # Bollinger Bands\n",
    "    \"BBP_10_2.0_10\",\n",
    "    \"BBL_15_2.0_15\",\n",
    "    \"BBM_15_2.0_15\",\n",
    "    \"BBU_15_2.0_15\",\n",
    "    \"BBB_15_2.0_15\",\n",
    "    \"BBP_15_2.0_15\",\n",
    "    \"BBL_20_2.0_20\",\n",
    "    \"BBM_20_2.0_20\",\n",
    "    \"BBU_20_2.0_20\",\n",
    "    \"BBB_20_2.0_20\",\n",
    "    \"BBP_20_2.0_20\",\n",
    "    \"bollinger_bandwidth\",\n",
    "    \"BBL_5_2.0_5\",\n",
    "    \"BBM_5_2.0_5\",\n",
    "    \"BBU_5_2.0_5\",\n",
    "    \"BBB_5_2.0_5\",\n",
    "    \"BBP_5_2.0_5\",\n",
    "    \"BBL_10_2.0_10\",\n",
    "    \"BBM_10_2.0_10\",\n",
    "    \"BBU_10_2.0_10\",\n",
    "    \"BBB_10_2.0_10\",\n",
    "    \"BBP_10_2.0_10\",\n",
    "    # Stochastic Oscillator\n",
    "    \"STOCHd_14_3_3\",\n",
    "    \"STOCHk_14_3_3_7_3_3\",\n",
    "    \"STOCHd_14_3_3_7_3_3\",\n",
    "    \"STOCHk_14_3_3_10_3_3\",\n",
    "    \"STOCHd_14_3_3_10_3_3\",\n",
    "    # Volatility\n",
    "    \"ATR_14\",\n",
    "    \"ATR_10\",\n",
    "    \"ATR_5\",\n",
    "    # Other momentum oscillators\n",
    "    \"ROC_14\",\n",
    "    \"ROC_10\",\n",
    "    \"ROC_5\",\n",
    "    # Other versatile indicators\n",
    "    \"CCI_14\",\n",
    "    \"CCI_10\",\n",
    "    \"CCI_5\",\n",
    "    # Money Flow Index and Chaikin Money Flow\n",
    "    \"cmf\",\n",
    "    \"mfi\",\n",
    "    # Relative Vigor Index (RVI)\n",
    "    \"RVI_15\",\n",
    "    \"RVI_10\",\n",
    "    \"RVI_5\",\n",
    "    # Pivot Points\n",
    "    \"PP\",\n",
    "    \"R1\",\n",
    "    \"S1\",\n",
    "    \"R2\",\n",
    "    \"S2\",\n",
    "    \"R3\",\n",
    "    \"S3\",\n",
    "    # Parabolic SAR (PSAR)\n",
    "    \"PSARl_0.01_0.1\",\n",
    "    \"PSARs_0.01_0.1\",\n",
    "    \"PSARaf_0.01_0.1\",\n",
    "    \"PSARr_0.01_0.1\",\n",
    "    # Triple Exponential Average (TRIX)\n",
    "    \"TRIX_18_9\",\n",
    "    \"TRIXs_18_9\",\n",
    "    \"TRIX_12_6\",\n",
    "    \"TRIXs_12_6\",\n",
    "    \"TRIX_10_5\",\n",
    "    \"TRIXs_10_5\",\n",
    "    # Ichimoku Cloud (ISA, ISB, ITS, IKS, ICS)\n",
    "    \"ISA_5\",\n",
    "    \"ISB_15\",\n",
    "    \"ITS_5\",\n",
    "    \"IKS_15\",\n",
    "    \"ICS_15\",\n",
    "]\n",
    "drop_features = [\n",
    "    \"MACDs_12_26_9\",\n",
    "    \"EMA_5\",\n",
    "    \"RVI_10\",\n",
    "    \"ISA_5\",\n",
    "    \"SMA_20\",\n",
    "    \"S2\",\n",
    "    \"BBM_10_2.0_10\",\n",
    "    \"PSARl_0.01_0.1\",\n",
    "    \"IKS_15\",\n",
    "    \"BBU_15_2.0_15\",\n",
    "    \"S1\",\n",
    "    \"PSARr_0.01_0.1\",\n",
    "    \"BBL_10_2.0_10\",\n",
    "    \"ATR_10\",\n",
    "    \"SMA_10\",\n",
    "    \"STOCHd_14_3_3_10_3_3\",\n",
    "    \"ICS_15\",\n",
    "    \"BBL_20_2.0_20\",\n",
    "    \"bollinger_bandwidth\",\n",
    "    \"BBL_5_2.0_5\",\n",
    "    \"PP\",\n",
    "    \"TRIX_12_6\",\n",
    "    \"volume\",\n",
    "    \"BBU_20_2.0_20\",\n",
    "    \"S3\",\n",
    "    \"R3\",\n",
    "    \"BBU_5_2.0_5\",\n",
    "    \"BBL_15_2.0_15\",\n",
    "    \"low\",\n",
    "    \"R1\",\n",
    "    \"BBU_10_2.0_10\",\n",
    "    \"close\",\n",
    "    \"BBM_15_2.0_15\",\n",
    "    \"R2\",\n",
    "    \"BBM_20_2.0_20\",\n",
    "    \"high\",\n",
    "    \"ISB_15\",\n",
    "    \"BBM_5_2.0_5\",\n",
    "    \"EMA_2\",\n",
    "    \"SMA_5\",\n",
    "    \"open\",\n",
    "    \"PSARs_0.01_0.1\",\n",
    "    \"ITS_5\",\n",
    "    \"EMA_10\",\n",
    "    \"PSARaf_0.01_0.1\",\n",
    "    \"ATR_14\",\n",
    "    \"MACD_6_13_5_6_13_5\",\n",
    "    \"cmf\",\n",
    "    \"CCI_14\",\n",
    "    \"STOCHk_14_3_3_10_3_3\",\n",
    "    \"TRIX_18_9\",\n",
    "    \"BBB_10_2.0_10\",\n",
    "    \"RSI_10\",\n",
    "    \"MACDh_6_13_5_6_13_5\",\n",
    "    \"TRIXs_10_5\",\n",
    "]\n",
    "\n",
    "# List of features to create lags for\n",
    "lag_features = [\n",
    "    \"turnover\",\n",
    "    \"CCI_5\",\n",
    "    \"BBP_5_2.0_5\",\n",
    "    \"color\",\n",
    "    \"BBP_10_2.0_10\",\n",
    "    \"RVI_5\",\n",
    "    \"CCI_10\",\n",
    "    \"BBB_5_2.0_5\",\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(50, activation=\"relu\", input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_lag_features(df, lag_features, max_lag):\n",
    "    for feature in lag_features:\n",
    "        for lag in range(1, max_lag + 1):\n",
    "            df[f\"{feature}_lag{lag}\"] = df[feature].shift(lag)\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_rolling_features(df, rolling_features, window_size):\n",
    "    for feature in rolling_features:\n",
    "        df[f\"{feature}_rolling_mean{window_size}\"] = (\n",
    "            df[feature].rolling(window_size).mean()\n",
    "        )\n",
    "        df[f\"{feature}_rolling_std{window_size}\"] = (\n",
    "            df[feature].rolling(window_size).std()\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(\n",
    "    \"../../../data/kc/btc/heiken_ashi/with_trade_indicators/raw/kc_btc_15min_ha_ti.csv\"\n",
    ")\n",
    "\n",
    "# Convert color to 0 for 'red' and 1 for 'green'\n",
    "df[\"color\"] = df[\"color\"].map({\"red\": 0, \"green\": 1})\n",
    "\n",
    "# Add 'color_change' column: 1 if color changes from the previous row, 0 otherwise\n",
    "df[\"color_change\"] = df[\"color\"].diff().abs()\n",
    "\n",
    "# Fill the first row's 'color_change' with 0\n",
    "df[\"color_change\"].fillna(0, inplace=True)\n",
    "\n",
    "# Drop 'time'\n",
    "df = df.drop([\"time\"], axis=1)\n",
    "\n",
    "# Drop the features\n",
    "df = df.drop(columns=drop_features)\n",
    "\n",
    "# Fill NaNs in specific columns with 0\n",
    "fill_cols = [\"PSARl_0.01_0.1\", \"PSARs_0.01_0.1\"]\n",
    "for col in fill_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(0)\n",
    "\n",
    "# Identify the first non-null row\n",
    "first_valid_index = df.dropna().index[0]\n",
    "\n",
    "# Drop the rows before this index in both features and target data\n",
    "df = df.loc[first_valid_index:]\n",
    "target = df[\"color_change\"].loc[first_valid_index:]\n",
    "\n",
    "# Use ffill to fill any remaining missing values\n",
    "df.ffill(inplace=True)\n",
    "\n",
    "# Separate the target column before scaling\n",
    "X = df.drop(\"color_change\", axis=1)\n",
    "y = df[\"color_change\"]\n",
    "\n",
    "# Initialize the Scaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Fit and transform the data to the scaler object\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Reset the index of target\n",
    "y = y.reset_index(drop=True)\n",
    "\n",
    "# print(df.head(20))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating lag features\n",
    "# df = create_lag_features(df, lag_features, max_lag=3)\n",
    "\n",
    "# # Fill NaNs\n",
    "# df.fillna(method=\"ffill\", inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target.reset_index(drop=True)\n",
    "\n",
    "data = X_scaled  # this is your scaled data\n",
    "target = y  # this is your target\n",
    "\n",
    "# number of splits\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "X_train_list = []\n",
    "X_test_list = []\n",
    "y_train_list = []\n",
    "y_test_list = []\n",
    "\n",
    "# for each split train a new model\n",
    "for train_index, test_index in tscv.split(data):\n",
    "    # separating the data into train and test splits\n",
    "    X_train, X_test = data[train_index], data[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "\n",
    "    # LSTM requires the input to be in the shape [samples, time steps, features]\n",
    "    # here we are using 1 time step and 'n' features\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "\n",
    "    # append to lists\n",
    "    X_train_list.append(X_train)\n",
    "    X_test_list.append(X_test)\n",
    "    y_train_list.append(y_train)\n",
    "    y_test_list.append(y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create LSTM model\n",
    "def create_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        LSTM(50, activation=\"relu\", input_shape=input_shape, return_sequences=True)\n",
    "    )\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(50, activation=\"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Initialize a list to store models\n",
    "models = []\n",
    "\n",
    "for i, (X_train, y_train) in enumerate(zip(X_train_list, y_train_list)):\n",
    "    # Initialize the model with the input shape\n",
    "    model = create_model((X_train.shape[1], X_train.shape[2]))\n",
    "\n",
    "    # We add an EarlyStopping callback from Keras to stop the training if the validation loss doesn't decrease for 5 consecutive epochs.\n",
    "    early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=50,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    # Append the trained model to the list\n",
    "    models.append(model)\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    # Predict the probabilities on the test set\n",
    "    y_pred_probs = model.predict(X_test_list[i])\n",
    "\n",
    "    # Convert probabilities into class labels\n",
    "    y_pred = [1 if prob > 0.5 else 0 for prob in y_pred_probs]\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    acc = accuracy_score(y_test_list[i], y_pred)\n",
    "\n",
    "    # Print the accuracy\n",
    "    print(f\"Model {i+1} accuracy: {acc:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 features: ['turnover', 'color', 'avg_vol_last_100', 'RSI_5', 'RSI_14', 'ATR_5', 'ROC_14', 'ROC_10', 'ROC_5', 'CCI_10', 'CCI_5', 'obv', 'mfi', 'RVI_15', 'RVI_5', 'TRIXs_18_9', 'TRIXs_12_6', 'TRIX_10_5', 'BBB_5_2.0_5', 'BBP_5_2.0_5', 'BBP_10_2.0_10', 'BBB_15_2.0_15', 'BBP_15_2.0_15', 'BBB_20_2.0_20', 'BBP_20_2.0_20', 'MACD_12_26_9', 'MACDh_12_26_9', 'MACDs_6_13_5_6_13_5', 'STOCHk_14_3_3', 'STOCHd_14_3_3', 'STOCHk_14_3_3_7_3_3', 'STOCHd_14_3_3_7_3_3']\n",
      "Model 2 features: ['turnover', 'color', 'avg_vol_last_100', 'RSI_5', 'RSI_14', 'ATR_5', 'ROC_14', 'ROC_10', 'ROC_5', 'CCI_10', 'CCI_5', 'obv', 'mfi', 'RVI_15', 'RVI_5', 'TRIXs_18_9', 'TRIXs_12_6', 'TRIX_10_5', 'BBB_5_2.0_5', 'BBP_5_2.0_5', 'BBP_10_2.0_10', 'BBB_15_2.0_15', 'BBP_15_2.0_15', 'BBB_20_2.0_20', 'BBP_20_2.0_20', 'MACD_12_26_9', 'MACDh_12_26_9', 'MACDs_6_13_5_6_13_5', 'STOCHk_14_3_3', 'STOCHd_14_3_3', 'STOCHk_14_3_3_7_3_3', 'STOCHd_14_3_3_7_3_3']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jnorm\\Projects\\websocket_trading\\.venv\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3 features: ['turnover', 'color', 'avg_vol_last_100', 'RSI_5', 'RSI_14', 'ATR_5', 'ROC_14', 'ROC_10', 'ROC_5', 'CCI_10', 'CCI_5', 'obv', 'mfi', 'RVI_15', 'RVI_5', 'TRIXs_18_9', 'TRIXs_12_6', 'TRIX_10_5', 'BBB_5_2.0_5', 'BBP_5_2.0_5', 'BBP_10_2.0_10', 'BBB_15_2.0_15', 'BBP_15_2.0_15', 'BBB_20_2.0_20', 'BBP_20_2.0_20', 'MACD_12_26_9', 'MACDh_12_26_9', 'MACDs_6_13_5_6_13_5', 'STOCHk_14_3_3', 'STOCHd_14_3_3', 'STOCHk_14_3_3_7_3_3', 'STOCHd_14_3_3_7_3_3']\n",
      "Model 1 Accuracy: 0.746885899352267\n",
      "Model 2 Accuracy: 0.7648231190832088\n",
      "Model 3 Accuracy: 0.7742899850523169\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store models\n",
    "models = []\n",
    "\n",
    "\n",
    "# Store feature names from DataFrame\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "for i, (X_train, y_train) in enumerate(zip(X_train_list, y_train_list)):\n",
    "    # Reshape data back into 2D because XGBoost does not accept 3D data like LSTM does\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[2])\n",
    "\n",
    "    # Also reshape X_test for eval_set\n",
    "    X_test = X_test_list[i].reshape(X_test_list[i].shape[0], X_test_list[i].shape[2])\n",
    "\n",
    "    # Initialize the model\n",
    "    model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        early_stopping_rounds=5,\n",
    "        eval_set=[(X_test, y_test_list[i])],\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    # Append the trained model to the list\n",
    "    models.append(model)\n",
    "\n",
    "    # Print feature names\n",
    "    print(f\"Model {i+1} features: {feature_names}\")\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    # Reshape data back into 2D because XGBoost does not accept 3D data like LSTM does\n",
    "    X_test = X_test_list[i].reshape(X_test_list[i].shape[0], X_test_list[i].shape[2])\n",
    "\n",
    "    # Predict the classes on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate the accuracy score\n",
    "    accuracy = accuracy_score(y_test_list[i], y_pred)\n",
    "\n",
    "    # Print the accuracy\n",
    "    print(f\"Model {i+1} Accuracy: {accuracy}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.6932 - accuracy: 0.5139 - val_loss: 0.6870 - val_accuracy: 0.5386\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6893 - accuracy: 0.5433 - val_loss: 0.6855 - val_accuracy: 0.5984\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6848 - accuracy: 0.5567 - val_loss: 0.6817 - val_accuracy: 0.6079\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6828 - accuracy: 0.5488 - val_loss: 0.6756 - val_accuracy: 0.5989\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6758 - accuracy: 0.5756 - val_loss: 0.6675 - val_accuracy: 0.6358\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6698 - accuracy: 0.5955 - val_loss: 0.6597 - val_accuracy: 0.6238\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6588 - accuracy: 0.6139 - val_loss: 0.6488 - val_accuracy: 0.6492\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6465 - accuracy: 0.6348 - val_loss: 0.6329 - val_accuracy: 0.6507\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6351 - accuracy: 0.6493 - val_loss: 0.6186 - val_accuracy: 0.7115\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6192 - accuracy: 0.6721 - val_loss: 0.6001 - val_accuracy: 0.7130\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6042 - accuracy: 0.6925 - val_loss: 0.5838 - val_accuracy: 0.7299\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5869 - accuracy: 0.7139 - val_loss: 0.5687 - val_accuracy: 0.7334\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5771 - accuracy: 0.7164 - val_loss: 0.5544 - val_accuracy: 0.7479\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5647 - accuracy: 0.7244 - val_loss: 0.5420 - val_accuracy: 0.7494\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5540 - accuracy: 0.7323 - val_loss: 0.5308 - val_accuracy: 0.7424\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5502 - accuracy: 0.7328 - val_loss: 0.5236 - val_accuracy: 0.7489\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5444 - accuracy: 0.7368 - val_loss: 0.5179 - val_accuracy: 0.7509\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5479 - accuracy: 0.7378 - val_loss: 0.5227 - val_accuracy: 0.7588\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5349 - accuracy: 0.7368 - val_loss: 0.5126 - val_accuracy: 0.7499\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5396 - accuracy: 0.7343 - val_loss: 0.5082 - val_accuracy: 0.7578\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5329 - accuracy: 0.7493 - val_loss: 0.5057 - val_accuracy: 0.7554\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5188 - accuracy: 0.7443 - val_loss: 0.5015 - val_accuracy: 0.7534\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5313 - accuracy: 0.7438 - val_loss: 0.5033 - val_accuracy: 0.7608\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5288 - accuracy: 0.7537 - val_loss: 0.4986 - val_accuracy: 0.7588\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5223 - accuracy: 0.7413 - val_loss: 0.4969 - val_accuracy: 0.7578\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5140 - accuracy: 0.7532 - val_loss: 0.4971 - val_accuracy: 0.7618\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5206 - accuracy: 0.7453 - val_loss: 0.4943 - val_accuracy: 0.7598\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5230 - accuracy: 0.7468 - val_loss: 0.4948 - val_accuracy: 0.7578\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5225 - accuracy: 0.7463 - val_loss: 0.4963 - val_accuracy: 0.7643\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5098 - accuracy: 0.7532 - val_loss: 0.4934 - val_accuracy: 0.7583\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5077 - accuracy: 0.7542 - val_loss: 0.4914 - val_accuracy: 0.7618\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5119 - accuracy: 0.7453 - val_loss: 0.4906 - val_accuracy: 0.7613\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5098 - accuracy: 0.7537 - val_loss: 0.4936 - val_accuracy: 0.7658\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5113 - accuracy: 0.7572 - val_loss: 0.4889 - val_accuracy: 0.7628\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5144 - accuracy: 0.7552 - val_loss: 0.4880 - val_accuracy: 0.7683\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5035 - accuracy: 0.7567 - val_loss: 0.4881 - val_accuracy: 0.7638\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5078 - accuracy: 0.7532 - val_loss: 0.4897 - val_accuracy: 0.7713\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5083 - accuracy: 0.7537 - val_loss: 0.4902 - val_accuracy: 0.7633\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5022 - accuracy: 0.7642 - val_loss: 0.4875 - val_accuracy: 0.7638\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5038 - accuracy: 0.7567 - val_loss: 0.4859 - val_accuracy: 0.7638\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4975 - accuracy: 0.7597 - val_loss: 0.4859 - val_accuracy: 0.7613\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4962 - accuracy: 0.7542 - val_loss: 0.4894 - val_accuracy: 0.7653\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5021 - accuracy: 0.7567 - val_loss: 0.4851 - val_accuracy: 0.7613\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5130 - accuracy: 0.7512 - val_loss: 0.4836 - val_accuracy: 0.7613\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4951 - accuracy: 0.7592 - val_loss: 0.4851 - val_accuracy: 0.7648\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5008 - accuracy: 0.7592 - val_loss: 0.4830 - val_accuracy: 0.7663\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5019 - accuracy: 0.7622 - val_loss: 0.4827 - val_accuracy: 0.7653\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4985 - accuracy: 0.7687 - val_loss: 0.4839 - val_accuracy: 0.7653\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5098 - accuracy: 0.7557 - val_loss: 0.4839 - val_accuracy: 0.7678\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5036 - accuracy: 0.7607 - val_loss: 0.4831 - val_accuracy: 0.7643\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6937 - accuracy: 0.5215 - val_loss: 0.6891 - val_accuracy: 0.5775\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6876 - accuracy: 0.5432 - val_loss: 0.6839 - val_accuracy: 0.5864\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6830 - accuracy: 0.5663 - val_loss: 0.6754 - val_accuracy: 0.6642\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6720 - accuracy: 0.6037 - val_loss: 0.6573 - val_accuracy: 0.6492\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6521 - accuracy: 0.6502 - val_loss: 0.6267 - val_accuracy: 0.7309\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6215 - accuracy: 0.6853 - val_loss: 0.5882 - val_accuracy: 0.7434\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5916 - accuracy: 0.7142 - val_loss: 0.5556 - val_accuracy: 0.7499\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5701 - accuracy: 0.7247 - val_loss: 0.5327 - val_accuracy: 0.7479\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5517 - accuracy: 0.7371 - val_loss: 0.5183 - val_accuracy: 0.7529\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5436 - accuracy: 0.7379 - val_loss: 0.5130 - val_accuracy: 0.7519\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5360 - accuracy: 0.7409 - val_loss: 0.5116 - val_accuracy: 0.7499\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5382 - accuracy: 0.7416 - val_loss: 0.5008 - val_accuracy: 0.7578\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5217 - accuracy: 0.7533 - val_loss: 0.4991 - val_accuracy: 0.7544\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5258 - accuracy: 0.7508 - val_loss: 0.4999 - val_accuracy: 0.7539\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5178 - accuracy: 0.7563 - val_loss: 0.5018 - val_accuracy: 0.7539\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5252 - accuracy: 0.7486 - val_loss: 0.5017 - val_accuracy: 0.7524\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5132 - accuracy: 0.7488 - val_loss: 0.4953 - val_accuracy: 0.7578\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5167 - accuracy: 0.7553 - val_loss: 0.4975 - val_accuracy: 0.7559\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5128 - accuracy: 0.7588 - val_loss: 0.4933 - val_accuracy: 0.7573\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5132 - accuracy: 0.7585 - val_loss: 0.4989 - val_accuracy: 0.7534\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5169 - accuracy: 0.7560 - val_loss: 0.4978 - val_accuracy: 0.7534\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5089 - accuracy: 0.7595 - val_loss: 0.4888 - val_accuracy: 0.7588\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5118 - accuracy: 0.7555 - val_loss: 0.4895 - val_accuracy: 0.7648\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5042 - accuracy: 0.7628 - val_loss: 0.4910 - val_accuracy: 0.7613\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5096 - accuracy: 0.7575 - val_loss: 0.4888 - val_accuracy: 0.7633\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5051 - accuracy: 0.7575 - val_loss: 0.4874 - val_accuracy: 0.7643\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.7595 - val_loss: 0.4858 - val_accuracy: 0.7668\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.7615 - val_loss: 0.4876 - val_accuracy: 0.7613\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5018 - accuracy: 0.7558 - val_loss: 0.4891 - val_accuracy: 0.7593\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4967 - accuracy: 0.7645 - val_loss: 0.4866 - val_accuracy: 0.7653\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7595 - val_loss: 0.4862 - val_accuracy: 0.7628\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5023 - accuracy: 0.7573 - val_loss: 0.4844 - val_accuracy: 0.7658\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4995 - accuracy: 0.7583 - val_loss: 0.4846 - val_accuracy: 0.7643\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4938 - accuracy: 0.7593 - val_loss: 0.4843 - val_accuracy: 0.7618\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5015 - accuracy: 0.7593 - val_loss: 0.4864 - val_accuracy: 0.7578\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4992 - accuracy: 0.7630 - val_loss: 0.4822 - val_accuracy: 0.7693\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4994 - accuracy: 0.7623 - val_loss: 0.4823 - val_accuracy: 0.7673\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4941 - accuracy: 0.7640 - val_loss: 0.4842 - val_accuracy: 0.7648\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4974 - accuracy: 0.7635 - val_loss: 0.4858 - val_accuracy: 0.7578\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4906 - accuracy: 0.7605 - val_loss: 0.4879 - val_accuracy: 0.7593\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4945 - accuracy: 0.7623 - val_loss: 0.4832 - val_accuracy: 0.7583\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4919 - accuracy: 0.7600 - val_loss: 0.4812 - val_accuracy: 0.7648\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4936 - accuracy: 0.7608 - val_loss: 0.4854 - val_accuracy: 0.7608\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4891 - accuracy: 0.7600 - val_loss: 0.4856 - val_accuracy: 0.7593\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4909 - accuracy: 0.7633 - val_loss: 0.4839 - val_accuracy: 0.7618\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4902 - accuracy: 0.7657 - val_loss: 0.4808 - val_accuracy: 0.7648\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4929 - accuracy: 0.7603 - val_loss: 0.4820 - val_accuracy: 0.7569\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7635 - val_loss: 0.4848 - val_accuracy: 0.7588\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4880 - accuracy: 0.7647 - val_loss: 0.4814 - val_accuracy: 0.7608\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4873 - accuracy: 0.7647 - val_loss: 0.4777 - val_accuracy: 0.7698\n",
      "Epoch 1/50\n",
      "48/48 [==============================] - 1s 6ms/step - loss: 0.6911 - accuracy: 0.5470 - val_loss: 0.6830 - val_accuracy: 0.6348\n",
      "Epoch 2/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.6764 - accuracy: 0.5891 - val_loss: 0.6599 - val_accuracy: 0.6129\n",
      "Epoch 3/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.6468 - accuracy: 0.6529 - val_loss: 0.6304 - val_accuracy: 0.6657\n",
      "Epoch 4/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.6046 - accuracy: 0.6916 - val_loss: 0.5824 - val_accuracy: 0.7275\n",
      "Epoch 5/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.5691 - accuracy: 0.7238 - val_loss: 0.5532 - val_accuracy: 0.7354\n",
      "Epoch 6/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.5572 - accuracy: 0.7291 - val_loss: 0.5370 - val_accuracy: 0.7394\n",
      "Epoch 7/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.5433 - accuracy: 0.7422 - val_loss: 0.5252 - val_accuracy: 0.7444\n",
      "Epoch 8/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.5343 - accuracy: 0.7432 - val_loss: 0.5199 - val_accuracy: 0.7429\n",
      "Epoch 9/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.5267 - accuracy: 0.7462 - val_loss: 0.5120 - val_accuracy: 0.7524\n",
      "Epoch 10/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.5238 - accuracy: 0.7508 - val_loss: 0.5119 - val_accuracy: 0.7469\n",
      "Epoch 11/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.5225 - accuracy: 0.7507 - val_loss: 0.5063 - val_accuracy: 0.7524\n",
      "Epoch 12/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.5190 - accuracy: 0.7498 - val_loss: 0.5052 - val_accuracy: 0.7573\n",
      "Epoch 13/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.5184 - accuracy: 0.7512 - val_loss: 0.4999 - val_accuracy: 0.7569\n",
      "Epoch 14/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.5152 - accuracy: 0.7470 - val_loss: 0.5016 - val_accuracy: 0.7524\n",
      "Epoch 15/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.5136 - accuracy: 0.7546 - val_loss: 0.4993 - val_accuracy: 0.7603\n",
      "Epoch 16/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.7566 - val_loss: 0.4956 - val_accuracy: 0.7564\n",
      "Epoch 17/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.5093 - accuracy: 0.7568 - val_loss: 0.4940 - val_accuracy: 0.7573\n",
      "Epoch 18/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.7621 - val_loss: 0.4925 - val_accuracy: 0.7613\n",
      "Epoch 19/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7537 - val_loss: 0.4926 - val_accuracy: 0.7598\n",
      "Epoch 20/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.5034 - accuracy: 0.7553 - val_loss: 0.4940 - val_accuracy: 0.7564\n",
      "Epoch 21/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7578 - val_loss: 0.4914 - val_accuracy: 0.7569\n",
      "Epoch 22/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.5030 - accuracy: 0.7600 - val_loss: 0.4924 - val_accuracy: 0.7564\n",
      "Epoch 23/50\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.4985 - accuracy: 0.7605 - val_loss: 0.4879 - val_accuracy: 0.7588\n",
      "Epoch 24/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.4930 - accuracy: 0.7674 - val_loss: 0.4874 - val_accuracy: 0.7569\n",
      "Epoch 25/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.4951 - accuracy: 0.7616 - val_loss: 0.4866 - val_accuracy: 0.7559\n",
      "Epoch 26/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.4915 - accuracy: 0.7625 - val_loss: 0.4847 - val_accuracy: 0.7588\n",
      "Epoch 27/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.4937 - accuracy: 0.7608 - val_loss: 0.4862 - val_accuracy: 0.7643\n",
      "Epoch 28/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.4919 - accuracy: 0.7625 - val_loss: 0.4842 - val_accuracy: 0.7638\n",
      "Epoch 29/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.4919 - accuracy: 0.7641 - val_loss: 0.4824 - val_accuracy: 0.7623\n",
      "Epoch 30/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.4951 - accuracy: 0.7616 - val_loss: 0.4814 - val_accuracy: 0.7588\n",
      "Epoch 31/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.4952 - accuracy: 0.7681 - val_loss: 0.4823 - val_accuracy: 0.7608\n",
      "Epoch 32/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.4909 - accuracy: 0.7603 - val_loss: 0.4806 - val_accuracy: 0.7623\n",
      "Epoch 33/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.4878 - accuracy: 0.7648 - val_loss: 0.4813 - val_accuracy: 0.7569\n",
      "Epoch 34/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.4900 - accuracy: 0.7673 - val_loss: 0.4793 - val_accuracy: 0.7633\n",
      "Epoch 35/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.4893 - accuracy: 0.7641 - val_loss: 0.4791 - val_accuracy: 0.7638\n",
      "Epoch 36/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.4913 - accuracy: 0.7641 - val_loss: 0.4779 - val_accuracy: 0.7628\n",
      "Epoch 37/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.4880 - accuracy: 0.7679 - val_loss: 0.4780 - val_accuracy: 0.7618\n",
      "Epoch 38/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.4892 - accuracy: 0.7613 - val_loss: 0.4774 - val_accuracy: 0.7603\n",
      "Epoch 39/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.4862 - accuracy: 0.7716 - val_loss: 0.4781 - val_accuracy: 0.7593\n",
      "Epoch 40/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.4873 - accuracy: 0.7618 - val_loss: 0.4767 - val_accuracy: 0.7608\n",
      "Epoch 41/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7688 - val_loss: 0.4753 - val_accuracy: 0.7648\n",
      "Epoch 42/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.4903 - accuracy: 0.7688 - val_loss: 0.4754 - val_accuracy: 0.7673\n",
      "Epoch 43/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.4853 - accuracy: 0.7656 - val_loss: 0.4774 - val_accuracy: 0.7653\n",
      "Epoch 44/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7621 - val_loss: 0.4786 - val_accuracy: 0.7618\n",
      "Epoch 45/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.4887 - accuracy: 0.7623 - val_loss: 0.4766 - val_accuracy: 0.7648\n",
      "Epoch 46/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.7664 - val_loss: 0.4753 - val_accuracy: 0.7628\n",
      "Epoch 47/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.4769 - accuracy: 0.7693 - val_loss: 0.4758 - val_accuracy: 0.7638\n",
      "Epoch 48/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.7666 - val_loss: 0.4755 - val_accuracy: 0.7658\n",
      "Epoch 49/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.4839 - accuracy: 0.7641 - val_loss: 0.4734 - val_accuracy: 0.7643\n",
      "Epoch 50/50\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.4776 - accuracy: 0.7673 - val_loss: 0.4741 - val_accuracy: 0.7653\n",
      "63/63 [==============================] - 0s 905us/step\n",
      "Model 1 Accuracy: 0.7643248629795715\n",
      "63/63 [==============================] - 0s 856us/step\n",
      "Model 2 Accuracy: 0.7698056801195815\n",
      "63/63 [==============================] - 0s 872us/step\n",
      "Model 3 Accuracy: 0.7653213751868461\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, Conv1D, MaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Initialize a list to store models\n",
    "models = []\n",
    "\n",
    "for i, (X_train, y_train) in enumerate(zip(X_train_list, y_train_list)):\n",
    "    # Reshape input data for 1D CNN (num_samples, num_features, num_channels)\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[2], 1)\n",
    "    X_test = X_test_list[i].reshape(X_test_list[i].shape[0], X_test_list[i].shape[2], 1)\n",
    "\n",
    "    # Initialize the 1D CNN model\n",
    "    model = Sequential(\n",
    "        [\n",
    "            Conv1D(\n",
    "                32, kernel_size=3, activation=\"relu\", input_shape=(X_train.shape[1], 1)\n",
    "            ),\n",
    "            MaxPooling1D(pool_size=2),\n",
    "            Dropout(0.25),\n",
    "            Flatten(),\n",
    "            Dense(64, activation=\"relu\"),\n",
    "            Dropout(0.5),\n",
    "            Dense(1, activation=\"sigmoid\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=50,\n",
    "        batch_size=128,\n",
    "        validation_data=(X_test, y_test_list[i]),\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    # Append the trained model to the list\n",
    "    models.append(model)\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    # Reshape input data for 1D CNN (num_samples, num_features, num_channels)\n",
    "    X_test = X_test_list[i].reshape(X_test_list[i].shape[0], X_test_list[i].shape[2], 1)\n",
    "\n",
    "    # Predict the probability of the chosen class on the test set\n",
    "    y_pred_proba = model.predict(X_test)\n",
    "\n",
    "    # Threshold prediction probabilities for binary classification\n",
    "    threshold = 0.5\n",
    "    y_pred = np.where(y_pred_proba > threshold, 1, 0)\n",
    "\n",
    "    # Calculate the accuracy score\n",
    "    accuracy = accuracy_score(y_test_list[i], y_pred)\n",
    "\n",
    "    # Print the accuracy\n",
    "    print(f\"Model {i+1} Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
