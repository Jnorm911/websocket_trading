{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1083,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    df = pd.read_csv(data_path)\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess_data(df):\n",
    "    # Convert 'color' column to binary representation\n",
    "    df[\"color\"] = df[\"color\"].map({\"red\": 0, \"green\": 1})\n",
    "\n",
    "    df[\"color_change\"] = df[\"color\"].diff().ne(0).astype(int)\n",
    "    df[\"color_change\"].fillna(0, inplace=True)\n",
    "\n",
    "    # Fill NaNs in specified columns with 0\n",
    "    df[\"PSARl_0.01_0.1\"].fillna(0, inplace=True)\n",
    "    df[\"PSARs_0.01_0.1\"].fillna(0, inplace=True)\n",
    "    df[\"ICS_15\"].fillna(0, inplace=True)\n",
    "\n",
    "    # duo diff features\n",
    "    df[\"open_close\"] = df[\"open\"] - df[\"close\"]\n",
    "    df[\"high_low\"] = df[\"high\"] - df[\"low\"]\n",
    "    df[\"close_change\"] = df[\"close\"].diff()\n",
    "    df[\"open_change\"] = df[\"open\"].diff()\n",
    "\n",
    "    # Create difference features for best performing features\n",
    "    diff_features = [\n",
    "        \"BBL_5_2.0_5\",\n",
    "        # \"BBU_5_2.0_5\",\n",
    "        # \"ATR_5\",\n",
    "        # \"ATR_10\",\n",
    "        # \"ATR_14\",\n",
    "        # \"high\",\n",
    "        # \"PSARaf_0.01_0.1\",\n",
    "        # \"BBU_10_2.0_10\",\n",
    "        # \"BBB_10_2.0_10\",\n",
    "        # \"BBL_10_2.0_10\",\n",
    "        # \"BBL_20_2.0_20\",\n",
    "        # \"bollinger_bandwidth\",\n",
    "        # \"PSARr_0.01_0.1\",\n",
    "        # \"S2\",\n",
    "        # \"S3\",\n",
    "        # \"ISB_15\",\n",
    "        # \"S1\",\n",
    "        # \"PSARl_0.01_0.1\",\n",
    "        # \"turnover\",\n",
    "        # \"volume\",\n",
    "    ]\n",
    "\n",
    "    for feature in diff_features:\n",
    "        df[f\"{feature}_diff\"] = df[feature].diff()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def scale_data(df):\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "    return df_scaled"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Globals ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set display options to show all rows and columns\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Load the data\n",
    "data_path = (\n",
    "    \"../../../data/kc/btc/heiken_ashi/with_trade_indicators/raw/kc_btc_12min_ha_ti.csv\"\n",
    ")\n",
    "\n",
    "# List of features to drop\n",
    "features_to_drop = [\n",
    "    ## Set 3\n",
    "    \"ROC_5\",\n",
    "    \"EMA_5\",\n",
    "    \"PP\",\n",
    "    \"RSI_5\",\n",
    "    \"MACDh_12_26_9\",\n",
    "    \"BBL_15_2.0_15\",\n",
    "    \"BBM_15_2.0_15\",\n",
    "    \"MACDs_6_13_5_6_13_5\",\n",
    "    \"BBB_20_2.0_20\",\n",
    "    \"STOCHd_14_3_3\",\n",
    "    \"TRIX_12_6\",\n",
    "    \"STOCHk_14_3_3_10_3_3\",\n",
    "    ## Set 2\n",
    "    \"BBP_5_2.0_5\",\n",
    "    \"RVI_15\",\n",
    "    \"obv\",\n",
    "    \"BBU_15_2.0_15\",\n",
    "    \"SMA_10\",\n",
    "    \"BBM_10_2.0_10\",\n",
    "    \"ICS_15\",\n",
    "    \"TRIXs_10_5\",\n",
    "    \"STOCHd_14_3_3_7_3_3\",\n",
    "    \"PSARs_0.01_0.1\",\n",
    "    ## Set 1\n",
    "    \"BBU_20_2.0_20\",\n",
    "    \"ROC_10\",\n",
    "    \"STOCHk_14_3_3_10_3_3\",\n",
    "    \"MACDs_12_26_9\",\n",
    "    \"CCI_5\",\n",
    "    \"BBM_20_2.0_20\",\n",
    "    \"SMA_5\",\n",
    "    \"RSI_14\",\n",
    "    ## Set 0\n",
    "    \"low\",\n",
    "    \"volume\",\n",
    "    \"close\",\n",
    "    \"avg_vol_last_100\",\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1085,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(data_path)\n",
    "\n",
    "# Preprocess the data\n",
    "df = preprocess_data(df)\n",
    "\n",
    "# Drop the specified features\n",
    "df = df.drop(columns=features_to_drop, errors=\"ignore\")\n",
    "\n",
    "# Prepare TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1086,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward Fill\n",
    "df.ffill(inplace=True)\n",
    "\n",
    "# Backward Fill\n",
    "df.bfill(inplace=True)\n",
    "\n",
    "# Re-scale the data to include the new feature\n",
    "df_scaled = scale_data(df)\n",
    "\n",
    "# print(df.isna().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIFF Ablation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1087,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initial DataFrame for scaling\n",
    "# df_initial = df.copy()\n",
    "\n",
    "# # List of all possible features\n",
    "# possible_features = list(df.columns)\n",
    "\n",
    "# # We want to ignore the target column 'color_change'\n",
    "# possible_features.remove(\"color_change\")\n",
    "\n",
    "# # A dictionary to store each feature and its associated score\n",
    "# feature_scores = {}\n",
    "\n",
    "# for feature in possible_features:\n",
    "#     # Reset the DataFrame to initial state\n",
    "#     df = df_initial.copy()\n",
    "\n",
    "#     # Add the difference feature\n",
    "#     df[f\"{feature}_diff\"] = df[feature].diff()\n",
    "\n",
    "#     # Forward Fill\n",
    "#     df.ffill(inplace=True)\n",
    "\n",
    "#     # Backward Fill\n",
    "#     df.bfill(inplace=True)\n",
    "\n",
    "#     # Keep a copy of the target variable\n",
    "#     color_change = df[\"color_change\"]\n",
    "\n",
    "#     # Re-scale the data to include the new feature (excluding the target variable)\n",
    "#     df_scaled = scale_data(df.drop(\"color_change\", axis=1))\n",
    "\n",
    "#     # Add the target variable back to the DataFrame\n",
    "#     df_scaled[\"color_change\"] = color_change\n",
    "\n",
    "#     # Prepare features and target\n",
    "#     X = df_scaled.drop(\"color_change\", axis=1)\n",
    "#     y = df_scaled[\"color_change\"]\n",
    "\n",
    "#     # Logistic Regression\n",
    "#     log_reg = LogisticRegression(random_state=42, max_iter=500)\n",
    "\n",
    "#     # Cross-validation\n",
    "#     cv_scores = cross_val_score(log_reg, X, y, cv=tscv, scoring=\"roc_auc\")\n",
    "\n",
    "#     # Add the score to the dictionary, using the feature name as the key\n",
    "#     feature_scores[feature] = np.mean(cv_scores)\n",
    "\n",
    "# # Now, you can print out the features and their scores, sorted by the score\n",
    "# for feature, score in sorted(\n",
    "#     feature_scores.items(), key=lambda item: item[1], reverse=True\n",
    "# ):\n",
    "#     print(f\"{feature}: {score}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1088,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression CV ROC AUC score: 0.5547205360485506\n",
      "Random Forest CV ROC AUC score: 0.8492430642567098\n",
      "\n",
      " Index(['time', 'open', 'high', 'turnover', 'color', 'R1', 'S1', 'R2', 'S2',\n",
      "       'R3', 'S3', 'RSI_10', 'ATR_14', 'ATR_10', 'ATR_5', 'ROC_14', 'CCI_14',\n",
      "       'CCI_10', 'cmf', 'mfi', 'RVI_10', 'RVI_5', 'PSARl_0.01_0.1',\n",
      "       'PSARaf_0.01_0.1', 'PSARr_0.01_0.1', 'TRIX_18_9', 'TRIXs_18_9',\n",
      "       'TRIXs_12_6', 'TRIX_10_5', 'SMA_20', 'EMA_2', 'EMA_10', 'ISA_5',\n",
      "       'ISB_15', 'ITS_5', 'IKS_15', 'BBL_5_2.0_5', 'BBM_5_2.0_5',\n",
      "       'BBU_5_2.0_5', 'BBB_5_2.0_5', 'BBL_10_2.0_10', 'BBU_10_2.0_10',\n",
      "       'BBB_10_2.0_10', 'BBP_10_2.0_10', 'BBB_15_2.0_15', 'BBP_15_2.0_15',\n",
      "       'BBL_20_2.0_20', 'BBP_20_2.0_20', 'bollinger_bandwidth', 'MACD_12_26_9',\n",
      "       'MACD_6_13_5_6_13_5', 'MACDh_6_13_5_6_13_5', 'STOCHk_14_3_3',\n",
      "       'STOCHk_14_3_3_7_3_3', 'STOCHd_14_3_3_10_3_3', 'open_close', 'high_low',\n",
      "       'close_change', 'open_change', 'BBL_5_2.0_5_diff', 'BBB_5_2.0_5_diff'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Prepare your features and target\n",
    "X = df.drop(\"color_change\", axis=1)\n",
    "y = df[\"color_change\"]\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=500)\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(log_reg, X, y, cv=tscv, scoring=\"roc_auc\")\n",
    "\n",
    "print(f\"Logistic Regression CV ROC AUC score: {np.mean(cv_scores)}\")\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(rf, X, y, cv=tscv, scoring=\"roc_auc\")\n",
    "\n",
    "print(f\"Random Forest CV ROC AUC score: {np.mean(cv_scores)}\")\n",
    "\n",
    "print(\"\\n\", X.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1089,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute pairwise correlation of columns\n",
    "# corr = df.corr()\n",
    "\n",
    "# # Set a lower threshold for correlations you want to display\n",
    "# threshold = -0.6\n",
    "\n",
    "# # Extract feature pairs with correlations below the threshold\n",
    "# filtered_correlations = corr.stack().reset_index()\n",
    "# filtered_correlations.columns = [\"Feature 1\", \"Feature 2\", \"Correlation\"]\n",
    "# filtered_correlations = filtered_correlations[\n",
    "#     (filtered_correlations[\"Feature 1\"] != filtered_correlations[\"Feature 2\"])\n",
    "#     & (filtered_correlations[\"Correlation\"] <= threshold)\n",
    "# ]\n",
    "\n",
    "# # Sort the filtered correlations by value and remove duplicates\n",
    "# filtered_correlations = filtered_correlations.sort_values(\n",
    "#     by=\"Correlation\", ascending=True\n",
    "# ).drop_duplicates()\n",
    "# print(filtered_correlations)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Read ablation file ##\n",
    "\n",
    "# # Load the DataFrame\n",
    "# df = pd.read_csv(\"model_accuracy_results.csv\")\n",
    "\n",
    "# # Sort the DataFrame by 'accuracy' from lowest to highest\n",
    "# df_sorted = df.sort_values(by=\"accuracy\", ascending=False)\n",
    "\n",
    "# # # Sample 50% of the DataFrame\n",
    "# # df_sampled = df_sorted.sample(frac=0.5)\n",
    "\n",
    "# # Display the sampled DataFrame\n",
    "# print(df_sorted)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablation ##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
