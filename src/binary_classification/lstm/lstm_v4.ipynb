{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFECV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    df = pd.read_csv(data_path)\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess_data(df):\n",
    "    # Convert 'color' column to binary representation\n",
    "    df[\"color\"] = df[\"color\"].map({\"red\": 0, \"green\": 1})\n",
    "\n",
    "    df[\"color_change\"] = df[\"color\"].diff().ne(0).astype(int)\n",
    "    df[\"color_change\"].fillna(0, inplace=True)\n",
    "\n",
    "    # Fill NaNs in specified columns with 0\n",
    "    df[\"PSARl_0.01_0.1\"].fillna(0, inplace=True)\n",
    "    df[\"PSARs_0.01_0.1\"].fillna(0, inplace=True)\n",
    "    df[\"ICS_15\"].fillna(0, inplace=True)\n",
    "\n",
    "    # Diff features\n",
    "\n",
    "    df[\"volume_diff\"] = df[\"volume\"].diff()\n",
    "    df[\"turnover_diff\"] = df[\"turnover\"].diff()\n",
    "    df[\"close_open\"] = df[\"close\"] - df[\"open\"]\n",
    "    df[\"open_close\"] = df[\"open\"] - df[\"close\"]\n",
    "    df[\"high_low\"] = df[\"high\"] - df[\"low\"]\n",
    "    df[\"close_change\"] = df[\"close\"].diff()\n",
    "    df[\"open_change\"] = df[\"open\"].diff()\n",
    "    df[\"h_diff\"] = df[\"high\"] - df[\"high\"].shift(1)\n",
    "    df[\"l_diff\"] = df[\"low\"] - df[\"low\"].shift(1)\n",
    "    df[\"hl_shift\"] = df[\"high\"] - df[\"low\"].shift(1)\n",
    "    df[\"high_pct\"] = df[\"high\"].pct_change()\n",
    "    df[\"low_pct\"] = df[\"low\"].pct_change()\n",
    "    df[\"close_open_lag\"] = df[\"close_open\"].shift(1)\n",
    "    df[\"high_low_lag\"] = df[\"high_low\"].shift(1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def scale_data(df):\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "    return df_scaled"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Globals ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set display options to show all rows and columns\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Load the data\n",
    "data_path = (\n",
    "    \"../../../data/kc/btc/heiken_ashi/with_trade_indicators/raw/kc_btc_12min_ha_ti.csv\"\n",
    ")\n",
    "\n",
    "# List of features to drop\n",
    "features_to_drop = [\n",
    "    ########\n",
    "    # Univariate Feature Selection Features #\n",
    "    #######\n",
    "    \"cmf\",\n",
    "    \"MACDs_6_13_5_6_13_5\",\n",
    "    \"RVI_10\",\n",
    "    \"BBL_5_2.0_5\",\n",
    "    \"STOCHk_14_3_3\",\n",
    "    \"STOCHk_14_3_3_7_3_3\",\n",
    "    \"STOCHk_14_3_3_10_3_3\",\n",
    "    \"MACDh_6_13_5_6_13_5\",\n",
    "    \"MACDh_12_26_9\",\n",
    "    \"BBL_10_2.0_10\",\n",
    "    \"R3\",\n",
    "    \"R2\",\n",
    "    \"R1\",\n",
    "    \"open\",\n",
    "    \"BBL_15_2.0_15\",\n",
    "    \"SMA_5\",\n",
    "    \"BBM_5_2.0_5\",\n",
    "    \"PP\",\n",
    "    \"BBL_20_2.0_20\",\n",
    "    \"EMA_5\",\n",
    "    \"ITS_5\",\n",
    "    \"SMA_10\",\n",
    "    \"BBM_10_2.0_10\",\n",
    "    \"EMA_10\",\n",
    "    \"S1\",\n",
    "    \"SMA_20\",\n",
    "    \"EMA_2\",\n",
    "    \"BBM_15_2.0_15\",\n",
    "    \"S2\",\n",
    "    \"BBM_20_2.0_20\",\n",
    "    \"IKS_15\",\n",
    "    \"close\",\n",
    "    \"PSARaf_0.01_0.1\",\n",
    "    \"S3\",\n",
    "    \"MACD_6_13_5_6_13_5\",\n",
    "    \"ISA_5\",\n",
    "    \"ISB_15\",\n",
    "    \"BBU_15_2.0_15\",\n",
    "    \"BBU_10_2.0_10\",\n",
    "    \"BBB_15_2.0_15\",\n",
    "    \"obv\",\n",
    "    \"BBU_5_2.0_5\",\n",
    "    \"high\",\n",
    "    \"STOCHd_14_3_3\",\n",
    "    \"STOCHd_14_3_3_7_3_3\",\n",
    "    \"STOCHd_14_3_3_10_3_3\",\n",
    "    \"TRIXs_10_5\",\n",
    "    \"MACD_12_26_9\",\n",
    "    \"PSARs_0.01_0.1\",\n",
    "    \"TRIXs_18_9\",\n",
    "    \"ICS_15\",\n",
    "    \"ROC_10\",\n",
    "    \"BBB_20_2.0_20\",\n",
    "    \"bollinger_bandwidth\",\n",
    "    \"RVI_15\",\n",
    "    \"MACDs_12_26_9\",\n",
    "    \"PSARl_0.01_0.1\",\n",
    "    \"TRIX_18_9\",\n",
    "    \"TRIXs_12_6\",\n",
    "    \"ROC_5\",\n",
    "    \"BBU_20_2.0_20\",\n",
    "    \"low\",\n",
    "    \"TRIX_12_6\",\n",
    "    \"ROC_14\",\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(data_path)\n",
    "\n",
    "# Preprocess the data\n",
    "df = preprocess_data(df)\n",
    "\n",
    "# Drop the specified features\n",
    "df = df.drop(columns=features_to_drop, errors=\"ignore\")\n",
    "\n",
    "# Prepare TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward Fill\n",
    "df.ffill(inplace=True)\n",
    "\n",
    "# Backward Fill\n",
    "df.bfill(inplace=True)\n",
    "\n",
    "# Re-scale the data to include the new feature\n",
    "df_scaled = scale_data(df)\n",
    "\n",
    "# print(df.isna().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Scores\n",
      "CV ROC AUC score without cmf: 0.5765177753422486\n",
      "CV ROC AUC score without MACDs_6_13_5_6_13_5: 0.5765177753422486\n",
      "CV ROC AUC score without RVI_10: 0.5765177753422486\n",
      "CV ROC AUC score without BBL_5_2.0_5: 0.5765177753422486\n",
      "CV ROC AUC score without STOCHk_14_3_3: 0.5765177753422486\n",
      "CV ROC AUC score without STOCHk_14_3_3_7_3_3: 0.5765177753422486\n",
      "CV ROC AUC score without STOCHk_14_3_3_10_3_3: 0.5765177753422486\n",
      "CV ROC AUC score without MACDh_6_13_5_6_13_5: 0.5765177753422486\n",
      "CV ROC AUC score without MACDh_12_26_9: 0.5765177753422486\n",
      "CV ROC AUC score without BBL_10_2.0_10: 0.5765177753422486\n",
      "CV ROC AUC score without R3: 0.5765177753422486\n",
      "CV ROC AUC score without R2: 0.5765177753422486\n",
      "CV ROC AUC score without o_shift: 0.5765177753422486\n",
      "CV ROC AUC score without R1: 0.5765177753422486\n",
      "CV ROC AUC score without open: 0.5765177753422486\n",
      "CV ROC AUC score without BBL_15_2.0_15: 0.5765177753422486\n",
      "CV ROC AUC score without SMA_5: 0.5765177753422486\n",
      "CV ROC AUC score without BBM_5_2.0_5: 0.5765177753422486\n",
      "CV ROC AUC score without c_shift: 0.5765177753422486\n",
      "CV ROC AUC score without PP: 0.5765177753422486\n",
      "CV ROC AUC score without BBL_20_2.0_20: 0.5765177753422486\n",
      "CV ROC AUC score without EMA_5: 0.5765177753422486\n",
      "CV ROC AUC score without ITS_5: 0.5765177753422486\n",
      "CV ROC AUC score without SMA_10: 0.5765177753422486\n",
      "CV ROC AUC score without BBM_10_2.0_10: 0.5765177753422486\n",
      "CV ROC AUC score without EMA_10: 0.5765177753422486\n",
      "CV ROC AUC score without S1: 0.5765177753422486\n",
      "CV ROC AUC score without SMA_20: 0.5765177753422486\n",
      "CV ROC AUC score without EMA_2: 0.5765177753422486\n",
      "CV ROC AUC score without BBM_15_2.0_15: 0.5765177753422486\n",
      "CV ROC AUC score without S2: 0.5765177753422486\n",
      "CV ROC AUC score without BBM_20_2.0_20: 0.5765177753422486\n",
      "CV ROC AUC score without IKS_15: 0.5765177753422486\n",
      "CV ROC AUC score without close: 0.5765177753422486\n",
      "CV ROC AUC score without PSARaf_0.01_0.1: 0.5765177753422486\n",
      "CV ROC AUC score without S3: 0.5765177753422486\n",
      "CV ROC AUC score without MACD_6_13_5_6_13_5: 0.5765177753422486\n",
      "CV ROC AUC score without ISA_5: 0.5765177753422486\n",
      "CV ROC AUC score without ISB_15: 0.5765177753422486\n",
      "CV ROC AUC score without BBU_15_2.0_15: 0.5765177753422486\n",
      "CV ROC AUC score without BBU_10_2.0_10: 0.5765177753422486\n",
      "CV ROC AUC score without BBB_15_2.0_15: 0.5765177753422486\n",
      "CV ROC AUC score without BBU_5_2.0_5: 0.5765177753422486\n",
      "CV ROC AUC score without high: 0.5765177753422486\n",
      "CV ROC AUC score without STOCHd_14_3_3: 0.5765177753422486\n",
      "CV ROC AUC score without STOCHd_14_3_3_7_3_3: 0.5765177753422486\n",
      "CV ROC AUC score without STOCHd_14_3_3_10_3_3: 0.5765177753422486\n",
      "CV ROC AUC score without TRIXs_10_5: 0.5765177753422486\n",
      "CV ROC AUC score without MACD_12_26_9: 0.5765177753422486\n",
      "CV ROC AUC score without TRIXs_18_9: 0.5765177753422486\n",
      "CV ROC AUC score without ICS_15: 0.5765177753422486\n",
      "CV ROC AUC score without ROC_10: 0.5765177753422486\n",
      "CV ROC AUC score without BBB_20_2.0_20: 0.5765177753422486\n",
      "CV ROC AUC score without bollinger_bandwidth: 0.5765177753422486\n",
      "CV ROC AUC score without RVI_15: 0.5765177753422486\n",
      "CV ROC AUC score without MACDs_12_26_9: 0.5765177753422486\n",
      "CV ROC AUC score without TRIX_18_9: 0.5765177753422486\n",
      "CV ROC AUC score without volume_diff_lag: 0.5765177753422486\n",
      "CV ROC AUC score without TRIXs_12_6: 0.5765177753422486\n",
      "CV ROC AUC score without ROC_5: 0.5765177753422486\n",
      "CV ROC AUC score without BBU_20_2.0_20: 0.5765177753422486\n",
      "CV ROC AUC score without low: 0.5765177753422486\n",
      "CV ROC AUC score without TRIX_12_6: 0.5765177753422486\n",
      "CV ROC AUC score without ROC_14: 0.5765177753422486\n",
      "CV ROC AUC score without PSARs_0.01_0.1: 0.5765177749394741\n",
      "CV ROC AUC score without PSARl_0.01_0.1: 0.5765177745366995\n",
      "CV ROC AUC score without obv: 0.5765173536702544\n"
     ]
    }
   ],
   "source": [
    "# Define initial features for ablation process\n",
    "ablation_features = [\n",
    "    \"cmf\",\n",
    "    \"MACDs_6_13_5_6_13_5\",\n",
    "    \"RVI_10\",\n",
    "    \"BBL_5_2.0_5\",\n",
    "    \"STOCHk_14_3_3\",\n",
    "    \"STOCHk_14_3_3_7_3_3\",\n",
    "    \"STOCHk_14_3_3_10_3_3\",\n",
    "    \"MACDh_6_13_5_6_13_5\",\n",
    "    \"MACDh_12_26_9\",\n",
    "    \"BBL_10_2.0_10\",\n",
    "    \"R3\",\n",
    "    \"R2\",\n",
    "    \"o_shift\",\n",
    "    \"R1\",\n",
    "    \"open\",\n",
    "    \"BBL_15_2.0_15\",\n",
    "    \"SMA_5\",\n",
    "    \"BBM_5_2.0_5\",\n",
    "    \"c_shift\",\n",
    "    \"PP\",\n",
    "    \"BBL_20_2.0_20\",\n",
    "    \"EMA_5\",\n",
    "    \"ITS_5\",\n",
    "    \"SMA_10\",\n",
    "    \"BBM_10_2.0_10\",\n",
    "    \"EMA_10\",\n",
    "    \"S1\",\n",
    "    \"SMA_20\",\n",
    "    \"EMA_2\",\n",
    "    \"BBM_15_2.0_15\",\n",
    "    \"S2\",\n",
    "    \"BBM_20_2.0_20\",\n",
    "    \"IKS_15\",\n",
    "    \"close\",\n",
    "    \"PSARaf_0.01_0.1\",\n",
    "    \"S3\",\n",
    "    \"MACD_6_13_5_6_13_5\",\n",
    "    \"ISA_5\",\n",
    "    \"ISB_15\",\n",
    "    \"BBU_15_2.0_15\",\n",
    "    \"BBU_10_2.0_10\",\n",
    "    \"BBB_15_2.0_15\",\n",
    "    \"obv\",\n",
    "    \"BBU_5_2.0_5\",\n",
    "    \"high\",\n",
    "    \"STOCHd_14_3_3\",\n",
    "    \"STOCHd_14_3_3_7_3_3\",\n",
    "    \"STOCHd_14_3_3_10_3_3\",\n",
    "    \"TRIXs_10_5\",\n",
    "    \"MACD_12_26_9\",\n",
    "    \"PSARs_0.01_0.1\",\n",
    "    \"TRIXs_18_9\",\n",
    "    \"ICS_15\",\n",
    "    \"ROC_10\",\n",
    "    \"BBB_20_2.0_20\",\n",
    "    \"bollinger_bandwidth\",\n",
    "    \"RVI_15\",\n",
    "    \"MACDs_12_26_9\",\n",
    "    \"PSARl_0.01_0.1\",\n",
    "    \"TRIX_18_9\",\n",
    "    \"volume_diff_lag\",\n",
    "    \"TRIXs_12_6\",\n",
    "    \"ROC_5\",\n",
    "    \"BBU_20_2.0_20\",\n",
    "    \"low\",\n",
    "    \"TRIX_12_6\",\n",
    "    \"ROC_14\",\n",
    "]\n",
    "\n",
    "# All the features in the data\n",
    "all_features = list(df.columns)\n",
    "all_features.remove(\"color_change\")  # we remove the target variable\n",
    "\n",
    "log_reg_scores = {}\n",
    "rf_scores = {}\n",
    "\n",
    "for feature in ablation_features:\n",
    "    # Remove one feature from the all features list\n",
    "    current_features = [f for f in all_features if f != feature]\n",
    "\n",
    "    # Prepare your features and target\n",
    "    X = df[current_features]\n",
    "    y = df[\"color_change\"]\n",
    "\n",
    "    # Logistic Regression\n",
    "    log_reg = LogisticRegression(random_state=42, max_iter=500)\n",
    "\n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(log_reg, X, y, cv=tscv, scoring=\"roc_auc\")\n",
    "    log_reg_scores[feature] = np.mean(cv_scores)\n",
    "\n",
    "# Print logistic regression scores sorted by score\n",
    "print(\"Logistic Regression Scores\")\n",
    "for feature, score in sorted(\n",
    "    log_reg_scores.items(), key=lambda item: item[1], reverse=True\n",
    "):\n",
    "    print(f\"CV ROC AUC score without {feature}: {score}\")\n",
    "\n",
    "for feature in ablation_features:\n",
    "    # Remove one feature from the all features list\n",
    "    current_features = [f for f in all_features if f != feature]\n",
    "\n",
    "    # Prepare your features and target\n",
    "    X = df[current_features]\n",
    "    y = df[\"color_change\"]\n",
    "\n",
    "    # Random Forest\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(rf, X, y, cv=tscv, scoring=\"roc_auc\")\n",
    "    rf_scores[feature] = np.mean(cv_scores)\n",
    "\n",
    "# Print random forest scores sorted by score\n",
    "print(\"\\nRandom Forest Scores\")\n",
    "for feature, score in sorted(rf_scores.items(), key=lambda item: item[1], reverse=True):\n",
    "    print(f\"CV ROC AUC score without {feature}: {score}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse Ablation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define initial features for ablation process\n",
    "# ablation_features = [\n",
    "#     \"cmf\",\n",
    "#     \"MACDs_6_13_5_6_13_5\",\n",
    "#     \"RVI_10\",\n",
    "#     \"BBL_5_2.0_5\",\n",
    "#     \"STOCHk_14_3_3\",\n",
    "#     \"STOCHk_14_3_3_7_3_3\",\n",
    "#     \"STOCHk_14_3_3_10_3_3\",\n",
    "#     \"MACDh_6_13_5_6_13_5\",\n",
    "#     \"MACDh_12_26_9\",\n",
    "#     \"BBL_10_2.0_10\",\n",
    "#     \"R3\",\n",
    "#     \"R2\",\n",
    "#     \"o_shift\",\n",
    "#     \"R1\",\n",
    "#     \"open\",\n",
    "#     \"BBL_15_2.0_15\",\n",
    "#     \"SMA_5\",\n",
    "#     \"BBM_5_2.0_5\",\n",
    "#     \"c_shift\",\n",
    "#     \"PP\",\n",
    "#     \"BBL_20_2.0_20\",\n",
    "#     \"EMA_5\",\n",
    "#     \"ITS_5\",\n",
    "#     \"SMA_10\",\n",
    "#     \"BBM_10_2.0_10\",\n",
    "#     \"EMA_10\",\n",
    "#     \"S1\",\n",
    "#     \"SMA_20\",\n",
    "#     \"EMA_2\",\n",
    "#     \"BBM_15_2.0_15\",\n",
    "#     \"S2\",\n",
    "#     \"BBM_20_2.0_20\",\n",
    "#     \"IKS_15\",\n",
    "#     \"close\",\n",
    "#     \"PSARaf_0.01_0.1\",\n",
    "#     \"S3\",\n",
    "#     \"MACD_6_13_5_6_13_5\",\n",
    "#     \"ISA_5\",\n",
    "#     \"ISB_15\",\n",
    "#     \"BBU_15_2.0_15\",\n",
    "#     \"BBU_10_2.0_10\",\n",
    "#     \"BBB_15_2.0_15\",\n",
    "#     \"obv\",\n",
    "#     \"BBU_5_2.0_5\",\n",
    "#     \"high\",\n",
    "#     \"STOCHd_14_3_3\",\n",
    "#     \"STOCHd_14_3_3_7_3_3\",\n",
    "#     \"STOCHd_14_3_3_10_3_3\",\n",
    "#     \"TRIXs_10_5\",\n",
    "#     \"MACD_12_26_9\",\n",
    "#     \"PSARs_0.01_0.1\",\n",
    "#     \"TRIXs_18_9\",\n",
    "#     \"ICS_15\",\n",
    "#     \"ROC_10\",\n",
    "#     \"BBB_20_2.0_20\",\n",
    "#     \"bollinger_bandwidth\",\n",
    "#     \"RVI_15\",\n",
    "#     \"MACDs_12_26_9\",\n",
    "#     \"PSARl_0.01_0.1\",\n",
    "#     \"TRIX_18_9\",\n",
    "#     \"volume_diff_lag\",\n",
    "#     \"TRIXs_12_6\",\n",
    "#     \"ROC_5\",\n",
    "#     \"BBU_20_2.0_20\",\n",
    "#     \"low\",\n",
    "#     \"TRIX_12_6\",\n",
    "#     \"ROC_14\",\n",
    "# ]\n",
    "\n",
    "# # All the features in the data\n",
    "# all_features = list(df.columns)\n",
    "# all_features.remove(\"color_change\")  # we remove the target variable\n",
    "\n",
    "# # Base features are all features excluding the ones in the ablation list\n",
    "# base_features = [\n",
    "#     feature for feature in all_features if feature not in ablation_features\n",
    "# ]\n",
    "\n",
    "# log_reg_scores = {}\n",
    "# rf_scores = {}\n",
    "\n",
    "# for feature in ablation_features:\n",
    "#     # Add one feature from the ablation list\n",
    "#     current_features = base_features + [feature]\n",
    "\n",
    "#     # Prepare your features and target\n",
    "#     X = df[current_features]\n",
    "#     y = df[\"color_change\"]\n",
    "\n",
    "#     # Logistic Regression\n",
    "#     log_reg = LogisticRegression(random_state=42, max_iter=500)\n",
    "\n",
    "#     # Cross-validation\n",
    "#     cv_scores = cross_val_score(log_reg, X, y, cv=tscv, scoring=\"roc_auc\")\n",
    "#     log_reg_scores[feature] = np.mean(cv_scores)\n",
    "\n",
    "# # Print logistic regression scores sorted by score\n",
    "# print(\"Logistic Regression Scores\")\n",
    "# for feature, score in sorted(\n",
    "#     log_reg_scores.items(), key=lambda item: item[1], reverse=True\n",
    "# ):\n",
    "#     print(f\"CV ROC AUC score with {feature}: {score}\")\n",
    "\n",
    "# for feature in ablation_features:\n",
    "#     # Add one feature from the ablation list\n",
    "#     current_features = base_features + [feature]\n",
    "\n",
    "#     # Prepare your features and target\n",
    "#     X = df[current_features]\n",
    "#     y = df[\"color_change\"]\n",
    "\n",
    "#     # Random Forest\n",
    "#     rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "#     # Cross-validation\n",
    "#     cv_scores = cross_val_score(rf, X, y, cv=tscv, scoring=\"roc_auc\")\n",
    "#     rf_scores[feature] = np.mean(cv_scores)\n",
    "\n",
    "# # Print random forest scores sorted by score\n",
    "# print(\"\\nRandom Forest Scores\")\n",
    "# for feature, score in sorted(rf_scores.items(), key=lambda item: item[1], reverse=True):\n",
    "#     print(f\"CV ROC AUC score with {feature}: {score}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df.drop(\"color_change\", axis=1)\n",
    "# y = df[\"color_change\"]\n",
    "\n",
    "# # Re-scale the data to include the new feature\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# # Fit XGBoost model and get feature importances\n",
    "# xgb = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric=\"logloss\")\n",
    "# xgb.fit(X_scaled, y)\n",
    "\n",
    "# # Store the feature importances in a pandas series, then sort it in descending order\n",
    "# importances = pd.Series(xgb.feature_importances_, index=X.columns)\n",
    "# importances_sorted = importances.sort_values(ascending=False)\n",
    "\n",
    "# print(\"Feature importances:\")\n",
    "# print(importances_sorted)\n",
    "\n",
    "# # Now we can apply Logistic Regression and Random Forests using the features\n",
    "# # Logistic Regression\n",
    "# log_reg = LogisticRegression(random_state=42, max_iter=500)\n",
    "\n",
    "# # Cross-validation\n",
    "# cv_scores = cross_val_score(log_reg, X_scaled, y, cv=tscv, scoring=\"f1\")\n",
    "\n",
    "# print(f\"\\nLogistic Regression CV F1 score: {np.mean(cv_scores)}\")\n",
    "\n",
    "# # Random Forest\n",
    "# rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# # Cross-validation\n",
    "# cv_scores = cross_val_score(rf, X_scaled, y, cv=tscv, scoring=\"f1\")\n",
    "\n",
    "# print(f\"Random Forest CV F1 score: {np.mean(cv_scores)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df.drop(\"color_change\", axis=1)\n",
    "# y = df[\"color_change\"]\n",
    "\n",
    "# # Re-scale the data to include the new feature\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# # Recursive Feature Elimination\n",
    "# # Here we use Logistic Regression as the model to evaluate the feature importance\n",
    "# # You can replace it with any model you prefer\n",
    "# model = LogisticRegression(random_state=42, max_iter=500)\n",
    "# rfe = RFECV(model)\n",
    "# rfe.fit(X_scaled, y)\n",
    "\n",
    "# # Get the features ranking\n",
    "# feature_ranking = {\n",
    "#     feature_name: rank for feature_name, rank in zip(X.columns, rfe.ranking_)\n",
    "# }\n",
    "\n",
    "# # Sort and print the feature ranking\n",
    "# for feature_name, rank in sorted(feature_ranking.items(), key=lambda item: item[1]):\n",
    "#     print(f\"{feature_name}: {rank}\")\n",
    "\n",
    "# # Transform X to include only the selected features\n",
    "# X_transformed = rfe.transform(X_scaled)\n",
    "\n",
    "# # Logistic Regression with transformed features\n",
    "# log_reg = LogisticRegression(random_state=42, max_iter=500)\n",
    "\n",
    "# # Cross-validation\n",
    "# cv_scores = cross_val_score(log_reg, X_transformed, y, cv=tscv, scoring=\"f1\")\n",
    "\n",
    "# print(f\"\\nLogistic Regression CV F1 score: {np.mean(cv_scores)}\")\n",
    "\n",
    "# # Random Forest with transformed features\n",
    "# rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# # Cross-validation\n",
    "# cv_scores = cross_val_score(rf, X_transformed, y, cv=tscv, scoring=\"f1\")\n",
    "\n",
    "# print(f\"Random Forest CV F1 score: {np.mean(cv_scores)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Feature Selection Process ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df.drop(\"color_change\", axis=1)\n",
    "# y = df[\"color_change\"]\n",
    "\n",
    "# # Re-scale the data to include the new feature\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# # feature selection\n",
    "# selector = SelectKBest(score_func=f_classif, k=\"all\")\n",
    "# selector.fit(X_scaled, y)\n",
    "\n",
    "# # Get columns to keep and create new dataframe with those only\n",
    "# cols = selector.get_support(indices=True)\n",
    "# features_df_new = X.iloc[:, cols]\n",
    "\n",
    "# # Store the scores of each feature in a dictionary\n",
    "# feature_scores = {\n",
    "#     feature_name: score for feature_name, score in zip(X.columns, selector.scores_)\n",
    "# }\n",
    "\n",
    "# # Sort the dictionary by value in descending order and print the scores\n",
    "# for feature_name, score in sorted(\n",
    "#     feature_scores.items(), key=lambda item: item[1], reverse=True\n",
    "# ):\n",
    "#     print(f\"{feature_name}: {score}\")\n",
    "\n",
    "# # Now we can apply Logistic Regression and Random Forests on the new features_df_new\n",
    "# # Logistic Regression\n",
    "# log_reg = LogisticRegression(random_state=42, max_iter=500)\n",
    "\n",
    "# # Cross-validation\n",
    "# cv_scores = cross_val_score(log_reg, features_df_new, y, cv=tscv, scoring=\"f1\")\n",
    "\n",
    "# print(f\"\\nLogistic Regression CV F1 score: {np.mean(cv_scores)}\")\n",
    "\n",
    "# # Random Forest\n",
    "# rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# # Cross-validation\n",
    "# cv_scores = cross_val_score(rf, features_df_new, y, cv=tscv, scoring=\"f1\")\n",
    "\n",
    "# print(f\"Random Forest CV F1 score: {np.mean(cv_scores)}\")\n",
    "\n",
    "# print(\"\\n\", features_df_new.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression CV ROC AUC score: 0.5765167194219271\n",
      "Random Forest CV ROC AUC score: 0.8940717177408083\n",
      "\n",
      " Index(['time', 'volume', 'turnover', 'color', 'avg_vol_last_100', 'RSI_5',\n",
      "       'RSI_10', 'RSI_14', 'ATR_14', 'ATR_10', 'ATR_5', 'CCI_14', 'CCI_10',\n",
      "       'CCI_5', 'mfi', 'RVI_5', 'PSARr_0.01_0.1', 'TRIX_10_5', 'BBB_5_2.0_5',\n",
      "       'BBP_5_2.0_5', 'BBB_10_2.0_10', 'BBP_10_2.0_10', 'BBP_15_2.0_15',\n",
      "       'BBP_20_2.0_20', 'volume_diff', 'turnover_diff', 'close_open',\n",
      "       'open_close', 'high_low', 'close_change', 'open_change', 'h_diff',\n",
      "       'l_diff', 'hl_shift', 'high_pct', 'low_pct', 'close_open_lag',\n",
      "       'high_low_lag'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Prepare your features and target\n",
    "X = df.drop(\"color_change\", axis=1)\n",
    "y = df[\"color_change\"]\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=500)\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(log_reg, X, y, cv=tscv, scoring=\"roc_auc\")\n",
    "\n",
    "print(f\"Logistic Regression CV ROC AUC score: {np.mean(cv_scores)}\")\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(rf, X, y, cv=tscv, scoring=\"roc_auc\")\n",
    "\n",
    "print(f\"Random Forest CV ROC AUC score: {np.mean(cv_scores)}\")\n",
    "\n",
    "print(\"\\n\", X.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
